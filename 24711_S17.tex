\documentclass[12pt]{article}
\usepackage{latexsym}
\usepackage{amssymb,amsmath}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage[margin=0.75in]{geometry}
\allowdisplaybreaks

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{cor}{Corollary}
\newtheorem{lemma}[theorem]{Lemma}

\usepackage[T1]{fontenc}
\usepackage{ccfonts}
\setlength\parindent{0pt}

\begin{document}

\begin{center}
\textbf{24.711: Topics in Philosophical Logic} \\
Alexander H. Patel \\
{\tt alexanderpatel@college.harvard.edu} \\
Last Updated: \today
\end{center}

\tableofcontents

\section{Wednesday, February 15, 2017}

\subsection{Zeno's Paradox of the Arrow}

\begin{itemize}
    \itemsep0em 
    \item  An object is at rest during an interval iff it occupies only a
        single position during that interval (not during a moment of time).
        It's stationary during an instant only if the instant is contained in
        an interval during which it's at rest. 
    \item Ancient Greeks could only answer the question qualitatively because
        they couldn't measure time (although they could measure distances). Use
        a compass to make circles and form multiples of a unit length on a
        line.
    \item Can use a straight edge and compass to get an estimate of length to
        any precision up to a rational number, but no further.
    \item Aristotelian physics gives no good way of measuring a length of time.
        Earth, air, wind, fire all have natural motion (up, down), but because
        of acceleration you can't figure out good lengths of time - you need
        something that moves at a uniform speed. The natural motion of things
        in the heavens is circular, so you can use star movement to measure
        lengths of time (not as simple as one would think because Aristotle's
        system was geo-centric where the planets orbited in a circle about the
        earth).
    \item
        Need to be able to measure time and distance in order to measure speed
        and so to get close to a solution for the core question of what it
        means to be stationary.
    \item
        Galileo look at pendulum movement - he saw a smooth continuous movement
        that happens at intervals (PE being converted into KE). The
        Aristotelian saw chaotic movement in the pendulum (you are displacing
        the bob and it's swinging is it trying to go downward but being
        contained by the string). Aristotle didn't have the principle of
        balancing of forces on the bob. Aristotle's answer to the question of
        why the bob doesn't stop is that there is some nonsense with a vacuum
        of air being generated behind the bob and pushing it forward. We can
        measure time by dividing the length of the pendulum rod and noting the
        period is inversely related to the square of the length of the rod.
    \item
        Speed during an interval is the quotient of change of distance over
        change and time. Zeno gave us the idea of 0 speed over an interval, now
        we have a quantitative idea of non-zero speed during an interval. But
        we still have to account for the idea that the ball is at rest only at
        its apogee but at no other point in its path.
    \item 
        We can solve the ball problem by solving $x'(t) = 0$, where $x'$ is the
        limit of the difference quotient of $(x(t + h) - x(t))/h$. Aristotle
        thought that bodies were the only things that were real and that bodies
        aren't made up of points or surfaces. So we can't just think of the
        ball but also need to consider the position in spacetime of the ball -
        we need to think of the trajectory (potential positions occupied by the
        ball) as existent, even when the ball isn't there. But Aristotle argued
        that a line isn't made up of points so this doesn't play out well under
        Aristotelian physics - i.e. we can talk about velocities but not of
        instantaneous velocities.
    \item 
        Why does Aristotle preclude the solution of taking the derivative? Do
        we not just take the limit over smaller and smaller intervals about the
        instant? The Aristotelian post-Newton understood the limit as the
        continual dividing of the line into smaller pieces.
    \item
        Things change when we switch to dynamics - throw a ball up at some
        initial speed and the downward force of gravity will decelerate the
        ball until it reaches 0. But since acceleration is $dv/dt$ there's no
        good way to define instantaneous acceleration out of velocity, which is
        also a function.
    \item
        You know there are times when the ball is going up and times when the
        ball is going down. We want to say there is a time when the ball
        reaches its highest point when its velocity was 0, how do we know there
        was such a time? We could solve this with the IVT but we want to do
        this constructively by constructing the cut between positive velocities
        and negative velocities. Can we get the LUB principle from numbers just
        from the movement of the ball? If the LUB principle didn't hold for the
        numbers then there would points in the ball's flight where it didn't
        have any associated number for its height.
    \item 
        Most of what we can use real numbers for (measurements of things) we
        can get away with just rational numbers. Dedekind had originally the
        bad idea that we could get away with just rational numbers, but that
        was thrown out with $\sqrt{2}$ and the Ancients. Also need cube roots
        to deal with the roots of cubic polynomials. So the real numbers fall
        out of solving polynomials with rational coefficients - but this
        doesn't solve the ball problem because you have no reason to believe
        that the place where the ball is stationary is the root of an equation.
    \item 
        The Ancients don't allow for the idea that there is a point on a line
        that is defined by the all the points to the right of it or to the left
        of it. For the ball, there needs to be a top point to define the switch
        of signs.
    \item
        Is it true that there is a supremum of all the points achieved by the
        ball? Is the ball at rest at this point? What if the ball only achieves
        heights of rational numbers (so it skips between points) or if the ball
        has a hole at the maximum of its height curve?
    \item
        From Mathematica, you have a tire on a hubcap that each go through the
        same number of rotations - how does the hubcap not move much less
        distance than the tire? Galileo: the tire is just a polygon, the hubcap
        goes through places where there is no corner of the polygon
        instantaneously which is just a wacky idea.
    \item 
        Conclusion: you can't explain what is going on if you just think in
        terms of bodies and don't think about space and lines as being made up
        of points.
    \item
        An alternative view says that only bodies are real, and the bodies can
        be in different places but the places aren't real, just the bodies are
        (and the distance relations they have with each other). Kant disputed
        this view - if God made a single marble hand before anything else, then
        He could've made either a right hand or a left hand (it has to be one
        or the other), but if all we have is bodies with spatial relations then
        there is nothing different between a right hand and a left hand; but
        there is a difference between right hand and left hhand so there has to
        be something to account for the difference - you need position.
\end{itemize}

\section{Tuesday, February 21, 2017}

\subsection{Dedekind's Construction of $\mathbb{R}$}

\begin{itemize}
    \itemsep0em 
    \item  
        Jill starts at the bottom of a hill when Jack starts and the top and
        the reach the top/bottom at the same time. Is there a point where they
        are at the same elevation? Yes - take the set of all times when the
        difference in height was positive and then take the least upper bound.
        Most people say that it comes from their motion being continuous.
    \item
        Really early on people learned how to use numbers to measure things -
        at least from having to re-establish property lines after the flooding
        of the Nile. This entailed measurement by yardstick which always yield
        results in fractional form. But can we get these same numerical
        properties without actually deferring to the use of numbers? 
    \item
        The rationals as fractions seem very well understood - the gaps between
        them were less well understood. We know that all the rationals along
        the path will be reached by the ball - how can we justify whether there
        are non-rational points that are hit by the ball.
    \item
        Pythagoreans found that simple ratios of where you put your finger on
        the lyre string correspond to harmonic sounds, but then one of them
        discovered that there are length sthat aren't rationals. He
        didn't find it out by measurement but rather by reductio ad absurdum -
        finding the length of the diagonal of the square with side length 1. He
        showed that it can't be rational (and was thrown overboard for his
        discovery). So you have to have square roots if you want to do geometry
        like the Greeks (because of conic sections).
    \item
        There's a problem which is for any square find another square that has
        twice the area - it was known by Plato and was in the Meno - solve it
        by taking the diagonal of the first as the side length of the second.
        Can you do this with a cube? You can't do this with a compass and
        straight edge. The medeival Arabics pushed forward by going passed
        compass/straightedge and finding teh roots of a cubic equation without
        requiring that the length we're talking about can be one you can
        actually create with a compass and straightedge. That produced a whole
        new family of lengths never talked about by the Greeks. It was widely
        believed that you could create new numbers by constructing equations
        with irrational roots with only rational coefficients. For example $x^3
        = 2$ you would introduce $\sqrt[3]{2}$. It was widely thought that all
        the real numbers were got by solving such equations, but for example
        $\pi$ isn't.
    \item
        Cantor showed that there are many more real numbers that aren't
        solutions to equations than ones there are. The question at the end of
        the 19th century was how to get a picture of what the real line was
        like - how to fill in all the holes. Dedekind's answer was to introduce
        the cuts. To fill in all the gaps, we need a cut everywhere. He gave a
        criteria for what it would mean for $\mathbb{R}$ to be complete, and
        second to show that there really was such a thing as that complete
        system of real numbers. The algebraic properties of the real numbers
        are relatively easy to satisfy, and you need added properties in order
        to fill in all the gaps. The principle Dedekind proposed was the
        least-upper bound principle. He also wanted to convince people that
        this was final - that you couldn't go any further.
    \item
        Dedekind started by seeing if a geometric approach would suffice - he
        thought this was obvious - why? You also need a lot of (controversial)
        set theory to get Dedekind cuts, but the Dedekind cuts do reduce the
        reals to the rationals to the integers. Around this time, everyone
        considered the laws of geometry to be synthetic a priori (Kant), where
        we could only make sense of our sensory experience if we organized them
        into three-dimensional space. It seems dubious that the way we organize
        space should be the foundation of analysis because we have tons of
        applications of the real numbers that have nothing to do with space.
        Also, there's non-Euclidean geometry.
    \item
        Dedekind started by enumerating the rules needed for $\mathbb{R}$:
        field axioms, ordering, etc. But that doesn't distinguish from the
        rationals. You need something more: the completeness principle (LUB).
        Dedekind gives some axioms that the thought could answer the question
        of what the real numbers are, or at least he says the real numbers
        satisfy those structural features. Why is identifying the structural
        features enough to say that you've identified the real numbers? There
        are going to be lots of other algebraic systems that satisfy those
        axioms. You have to also give the intended model for those axioms. The
        physical line satisfies those axioms, but we have no reason to believe
        that any particular one is not the real number system. Also any
        complete model of those axioms is going to be isomorphic to any other.
        Why is giving the structure not enough?
    \item
        At the same time, Frege was investigating the foundations of
        arithmetic. He thought that the only principle he needed was Hume's
        Principle (two collections have the same elements iff there's a
        one-to-one correspondence between the elements). He showed you could
        get PA axioms from Hume's Principle, but he still asked: how do I know
        whether Julius Ceasar is a number? We expect a numeral to pick out a
        definite thing, but we can never do this with only axioms. Dedekind
        introduced the idea that the numerals don't have to stand for definite
        objects - that mathematics is rather about identifying structural
        properties, and that identifying the structure is all you can and need
        to do. 
\end{itemize}

\section{Wednesday, February 22, 2017}

\subsection{Dedekind's Construction of $\mathbb{R}$}

\begin{itemize}
    \item
        Dedekind asked: what further properties than the normal ordering and
        field properties are necessary to specify the real numbers?
        Completeness. His proposal is to create cuts of the rationals into two
        non-empty classes so that everything in the lower portion is less than
        everything in the upper portion. Completeness means that anytime you
        have such a cut there is a real number defining it. This principle
        amounts to the least-upper bound principle. He showed that this
        condition characterizes the real number system (up to isomorphism).
        Historically, people had made systems that purported to be the real
        numbers but it turned out that they left some numbers out. But Dedekind
        showed that you can't add anything to his system and get anything
        that's properly larger. 
    \item
        The isomorphism theorem says that if you have any two models of his
        axioms $a$ and $b$, you first define the positive integers of $a$ to be
        those that contain $0 \in a$ and are closed under succession (and
        define the positive integers of $b$ the same way), and then define a
        map between the two sets of natural numbers. This map is injective - if
        it weren't, then the set of integers that had mappings would have a LUB
        $b'$, and somewhere between $b'$ and $b' - 1$ you would have an integer
        that gets mapped. This lets you map the rationals of $a$ to the
        rationals of $b$, and so then we get an isomorphism of Dedekind cuts
        and so of the real numbers in $a$ and $b$. 
    \item
        So we've completely characterized the structure we're looking for - how
        do we know that there is something that exhibits that structure?
        Dedekind's response is to define the set of all cuts to be the real
        numbers and then show that this structure satisfies the axioms. So he
        takes the construction to be a sufficient answer to the question of
        what the real numbers are. But it feels like he's just given us
        something that is isomorphic to the real numbers. 
    \item
        Frege equivalently gives structural axioms for the natural numbers, but
        wasn't satisfied because he couldn't answer the question of whether
        Julius Caesar was a natural number. Hume's Principle is a structural
        property that only characterizes the natural numbers up to isomorphism.
    \item
        All we need to construct the natural numbers is an infinite set from
        which we can generate a simply infinite set, but that's non-trivial
        because, starting from Zeno's Paradox, there is a long line of people
        saying that we can't have an infinite set, just a potentially infinite
        set. They say that all we can do is give methods for taking a finite
        sequence and extending it, but the idea that we can treat an infinite
        set as a whole was long treated as contradictory. Dedekind thinks he
        can build an infinite set by taking the totality of objects of his
        thought and take a member of that totality S and form the thought "S is
        an object of one's thought", and then recursively do that. That's a
        one-to-one function from the objects of one's thought to the objects of
        one's though, but it isn't onto because one's ego isn't of the form "X
        is the object of my thought". This skirts the question of potentially
        vs. actually infinite because the totality of objects of thought is
        something given to you, not something constructed.
    \item 
        He says that the natural numbers are a "free created of the human mind"
        which he clarifies as being because they are a result of the process of
        abstraction specified above. This isn't completely new - Cantor does
        something similar when he wants to go beyond the natural numbers into
        the transfinite by looking at the different ways of ordering the
        collection and then defining an order isomorphism and then defining the
        order types as got from the orderings by the process of abstraction.
        You regard two orderings the same if their orderings are isomorphic
        (there's a bijection from one to the other that preserves the order).
        Or you can go even more abstract and say that two totalities are the
        same if there is a bijection between them, irrespective of ordering.
        That gives you the cardinal numbers. Aristotle also gets the objects of
        geometry similarly - he thought of them as ordinary solid bodies but we
        abstract away all the non-geometrical properties. Both Cantor and
        Dedekind were dipping into that tradition.
    \item
        In retrospect, it seems like this is a big transition from thinking of
        mathematical terms like "natural/real/complex number" as denoting
        definite things (not things known from sense-experience, but still
        definite entities) to thinking about them as if we can talk about them
        as definite things once we've characterized them up to isomorphism.
        Modern mathematicians are pretty much invariably subscribers to the
        latter view - you talk about mathematical objects, but mathematical
        objects are what they are because of their properties and properties
        only characterize up to isomorphism. There was a change in the way
        mathematicians talked about mathematical objects that philosophy was
        really slow to notice.
    \item
        Cantor also had a way of creating the real numbers out of the
        rationals. Cantor himself was interested in Fourier Series and when
        they converge, for him the idea that the real numbers were complete was
        cashed out by the idea that series converge whenever it's possible for
        them to converge. For any convergent sequence, we have $\forall k,
        \exists N$ such that $n > N \Rightarrow |a_n - a_N| < \frac{1}{k}$
        (Cauchy sequence). So one criterion for the completeness of the real
        numbers other than the LUB principle is the Cauchy criterion implies
        convergence for any sequence. You can derive one criterion from the
        other. Cantor then defined the equivalence relation between $\{x_n\}$
        and $\{y_n\}$ as for any $k$ there is a sequence term such that $y_n$
        and $x_n$ are arbitrarily close passed the sequence term. You can show
        that Dedekind's and Cantor's principles yield isomorphic copies of the
        real numbers. But the question never arose as to which of these is the
        genuine construction of the real numbers. It didn't occur to them to
        ask: what's a real number - a Dedekind cut or an equivalence class of
        Cauchy sequences?
    \item
        Hilbert's axiomitization of geometry: he gave the set of axioms and
        wasn't initially concerned with the question of whether the system was
        complete. We know we get a model of the geometry axioms if you take a
        point to be an ordered triple of real numbers (identify a point with
        its coordinate in $\mathbb{R}^3$, which doesn't have anything to do
        with space and yet is still a perfectly good model). You also get a
        perfectly good model if you identify a point with an ordered triple of
        algebraic numbers - so the geometric axioms do not require
        completeness. Later on, Hilbert started to worry about completeness and
        so he added an axiom in the 9th edition so that the new axiom system is
        complete. One of the axioms of the original system was the Archimedean
        axiom: you can construct a line segment out of a sub-segment so that
        there is some multiple of the sub-segment that will surpass the end of
        the larger segment. Traditionally, geometric axioms were supposed to
        represent three-dimensional space, but Hilbert rather didn't deny that
        the axioms describe physical space but didn't assume that they were
        about physical space. He said the axioms were about systems that
        satisfy those axioms, and nothing more - there's nothing more to being
        an intended model for the geometric axioms. This is similar to group
        theory - there's no intended model for group theory other than a system
        that satisfies those axioms. This is a real departure from the idea
        that mathematics has a definite subject matter.
    \item
        You can have a name without a referent - for example, "Cerberus" or
        other names that occur within myths. You don't have that with names
        like "Cherry" - there's a definite referent to the name "Cherry". But
        we have these numerals in mathematics (e.g. $\sqrt{2}$) that don't have
        a uniquely determined thing that they refer to. The issue with idea of
        identifying the square root of 2 with the set of all things that when
        squared is 2 is problematic because you can't square a set. And you
        can't identify it with any one object whose square is two for similar
        reasons. There's a worry that Dedekind gave us a construction of what
        he called the real numbers and long before him the Egyptians were using
        numerals that purported to be real numbers, so did the Ancient
        Egyptians refer to a Dedekind cut when they wrote down one such
        numeral? Or, possibly, could the real number signs not refer to
        entities but instead to some action, like the act of taking the
        successor with the natural numbers? Well, the numerals do correspond in
        an objective way similarly to how people's names objectively refer to
        people. If it were purely made up, then there wouldn't be a "correct"
        answer for question with real-numbered answers.
    \item
        Dedekind described what he was doing as the reduction of analysis to
        arithmetic, which was understood to have secure foundations. But
        analysis has less secure foundations because people didn't have a clear
        understanding of continuity and limits and what was required for a
        sequence to converge - there was just a general lack of clarity. It's
        more accurate to say that he reduced analysis to set theory or set
        theory plus arithmetic because what he needs to form the cuts is a lot
        of set theory. Looking back, it seems that he really did do something
        important for our understanding of the foundations of analysis, but it
        was not reducing analysis to arithmetic but rather constructing
        analysis within this theory of sets. Next time let's look at the
        axiomatic theory of sets and consider Dedekind's construction as a
        construction of the real numbers within set theory.

\end{itemize}

\section{Wednesday, March 1, 2017}

\subsection{Combinatorial Conception of Sets}

\begin{itemize}
    \itemsep0em 
    \item
        Last time we talked about Zermelo's axiom of set theory. One thing
        Zermelo wasn't addressing but were in the background were the
        paradoxes, which is why people responded to his proof of the
        well-ordering theorem with such uncertainty (their understanding of how
        sets work was shaken by the appearance of paradoxes). Formal set theory
        was still pretty new and their study only came to the foreground with
        Dedekind and Cantor and it seemed to fall immediately into
        contradiction.
    \item
        The most prominent of paradoxes was Russell's paradox - some sets are
        elements of themselves, so consider the set of sets that are not
        members of themselves. If you ask the question of whether that set is a
        member of itself, you get a contradiction. The paradox has a direct
        analogue about language - "dog" isn't a dog so it doesn't apply to
        itself, but the phrase "does not apply to itself" applies to itself iff
        it doesn't.
    \item
        Another paradox was with Cantor's study of ordinal numbers, he found
        that the ordinals were well ordered and for any well ordered set there
        is an ordinal that describes the order type of that set. Any ordinal is
        the order type of the ordinals less than it. But consider the
        collection of all ordinals, which is well ordered, and so there is a
        map from all the ordinals to all the ordinals less than some ordinal.
        Keep applying the map and then you get an infinite descending sequence
        which is a contradiction because the ordinals are supposedly well
        ordered. The semantic analogue is to take all the names of ordinals,
        there are only countably many names and so there are only countable
        many names of ordinals, but since there are uncountably many ordinals
        there are ordinals that aren't named. Since the ordinals are
        well-ordered there is some least ordinal is not named, but we have just
        specified a name for it. Also there is a least natural number nameable
        in fewer than 19 syllables. 
    \item
        Cantor showed that there are uncountably many real numbers by assuming
        that there are only countably many real numbers and then disproving the
        bijection by constructing a new real number not in the enumerated set.
        You can make a bijection $\mathbb{R} \rightarrow \{q_1, q_2, q_3,
        \ldots \in \mathbb{Q}\}$. He generalized the result to show that for
        any set there are more subsets of $S$ than the number of elements of
        $S$. But then take the set of all sets, the cardinal number of the
        power set of the set is larger than the cardinal number of the set
        itself. But the power set of all sets of sets is included in the set of
        all sets and so the cardinal number of the power set is less than or
        equal to the cardinal number of the set of all sets. There is no direct
        linguistic analogue but it came from the generalization of Cantor's
        real number uncountability proof. If we look at that theorem
        linguistically, we see that there are only countably many names for the
        uncountable $\mathbb{R}$, and then put the names in a list an use
        Cantor's procedure to construct a real number that is nameable but not
        on the list of all possible names.
    \item
        Cantor just rejected that there was such thing as the set of all sets.
        He thought there were theological implications. He wrote to the Pope
        (no response) and said that he was developing a theory of the actual
        infinite but there may be worries because the church teaches that only
        God is infinite. He says it isn't blasphemous because he says he has
        found an intermediate level between the finite and the absolutely
        infinite (transfinite) where the transfinite goes beyond what we
        ordinarely think of the finite, but it's not copmlete limitless. If you
        had something completely limitless then you can't number it or
        comprehend it mathematically - only God is at the level of the
        absolutely infinite which is above not just the finite but also the
        transfinite. So Cantor's work isn't bringing God down to the level of
        ordinary mathematicians, but rather he boosted God up to a level
        farther beyond the level of things that Earthly things are. 
    \item
        So there's these analogues between set theoretic paradoxes and semantic
        paradoxes. Zermelo didn't seem interested in the semantic part. Russell
        had the exact opposite attitude - he thought this showed a deep
        discontinuity in human's thought, one that was so profound because it
        manifested in a lot of different ways. How important is it to get a
        unified solution to the set of two paradoxes? It really seems like they
        are the same phenomenon. 
    \item
        This week we're going to look at a pardox that wasn't among the list of
        Russell's paradoxes - developed around 1960. You can't recursively pick
        sets as elements of other sets - there's no infinite descending chain.
        Say a set is well-founded if there aren't any infinite descending
        chains beginning with. Let $W$ be the set of all well-founded sets. If
        there were an infinite descending chain ending with $W$ then look at
        the chain the ends at the element which is an element of $W$ and so
        that chain is infinite and the element is not well-founded. So $W$ has
        to be well-founded. But then $W \in W$ and so there's an infinite chain
        ending at $W$ by picking $W$ for every link of the chain. Since no
        well-founded set is a member of itself, this paradox seems to reduce
        straight to Russell's Paradox. But it doesn't because you could have $A
        \in B \in A \in B \in \dots$. So no loops of any length around whereas
        Russell's paradox is just a loop of length one. This paradox turned
        people's attention to sets that are well-founded - but most sets that
        are useful for math are those that are well-founded. If you want to
        really think closely about set theory but your interest in set theory
        is just for finding a theory of sets that is useful for mathematics,
        then you can just stick with the well-founded sets.
    \item
        So there was an axiom proposed that said that all sets are
        well-founded. What amounts to the same thing is: for any non-empty set
        $S$, there is an element $s \in S$ such that $\forall t \in s, t \notin
        S$. Originally it was just adopted for convenience but it does yield a
        really pretty picture for what the universe of sets looks like. If we
        assume that the things that aren't sets form a set, then you get this
        picture of the theory of types. The crucial axiom for building out this
        structure is the axiom of ordered pairs - this allows you to put
        together two elements from different levels. This is the way that
        Zermelo was thinking about it but not the way that Russell and
        Whitehead were thinking about it. Cantor's paradox entails forming a
        set at some particular level, but the set of all sets must be at a
        level before which the set of all sets is formed and so there is no
        level where the set of all sets is at. Since a set is always formed at
        a level after the level at which its elements are formed, so you solve
        the same set of paradoxes. For the ordinals, each level of the
        hierarchy introduces a new ordinal. Each level of the hierarchy
        introduces exactly one new ordinal. So in order to get the collection
        of all the ordinals it would have to be formed at a stage after which
        you'd already gotten all the ordinals and so there is no collection of
        all the ordinals. So there's a response to all the set-theoretic
        paradoxes that comes just from trying to form a set that violates the
        foundation axiom. 
    \item
        So adding another axiom gave us the stronger system because it removes
        an inconsistency but does not introduce one. If you restrict the axioms
        of set theory to range only over well-founded sets. You can verify that
        each formula you get from an axiom of set theory by restricting the
        quantifier is a theorem of set theory. If you could derive a
        contradiction from the axioms of set theory including the axiom of
        foundation then you could get a contradiction in ZFC.
    \item
        The tradition, beginning with Cantor, is thinking about collections
        formed from contained elements and you need collections to be
        well-founded and so you get paradoxes if you don't restrict to
        well-founded collections. The opposite view is from Frege where you get
        sets by starting with concepts. Von Neumann thought that you get
        contradictions when you start forming sets that are really large ($>>>
        \mathbb{R}$) like the set of all the ordinals or the set of all the
        cardinals, etc. So forming sets that are way too big is impossible but
        formulating sets that are relatively small is okay. The range of a
        function on a set will be at most the same size as the domain set so
        then if the things in the domain aren't too many to form a set then the
        things in the range aren't too many to form a set, either. VN had the
        replacement principle and this more global principle that you can form
        sets unless they are too big, "too big" meaning things form a set
        unless those things are equinumerous with the entire universe. So if
        you have set that's soo big that if it's a set then the entire universe
        is a set then that set is not actually a set. So there's a different
        way of thinking about where the paradoxes come from by having sets that
        are just too big. Axel took this idea and build a whole set theory out
        of it. 
    \item
        This is the combinatorial conception of sets as collections. Next time
        we will think about sets from a logical point of view by starting with
        concepts and then get to sets by a process of abstraction.
\end{itemize}

\section{Monday, March 6, 2017}

\subsection{Logical Conception of Sets}

\begin{itemize}
    \itemsep0em 
    \item
        We've been talking about set theory, of which there are two
        conceptions. The combinatorial approach says that sets are collections
        built up from individual. The other idea is the logical conception of
        sets, where you gets sets by starting with concepts and forming sets by
        abstraction. This conception starts with Frege. Frege started out by
        looking at complex names like "the capital of France" and saw that the
        name was formed by "France" and the function sign "the capital of \_".
        "France" names something, but "the capital of" only becomes complete by
        begin supplanted by a name. Concepts are unsaturated and are not
        individuals because it needs another object to be completed. 
    \item
        We know what an incomplete building - there are still bricks and
        mortar, but just not enough to yield a whole. But what is it for a
        concept to be essentially incomplete? At the syntax level, you put a
        name into a concept-phrase; at the semantic level, you put an object
        into a concept to get a truth value. Someone might (incorrectly) think
        that Versailles was the capital of France and say "We're going to Paris
        and then going to the capital of France". But you can't substitute
        "Paris" for the latter reference because the person believes that the
        referrent of "the capital of France" is Versailles. Senses deal with
        things like this (i.e. belief contexts). Thinking about sentences as
        having the True/the False as their referrents turned out to be very
        fruitful because he could think as predicates as functions. This
        allowed standard operations with functions from basic algebra to be
        applied to concepts.
    \item
        Frege has individuals, functions, function signs with more than one
        argument, and second-level functions. Second-level functions: "someone
        is a wise philosopher" has a similar grammatical structure as "Socrates
        is a wise philosopher", so it looks like you have "\_ is a wise
        philosopher" as a concept which can take "Socrates" and "someone" as
        arguments. But in the latter case the individual about which you're
        talking is only indefinitely specified. Frege saw that this wouldn't
        work because of things like "Someone is wise" and "Someone is a
        philosopher" does not yield "Someone is a wise philosopher" and so the
        logical structure of the two is really quite different. Frege's idea is
        that "someone" is not a name, but rather a function sign that takes as
        its argument a concept. So "someone" is the property that a property
        has if there is at least one person who falls under ther latter. So
        things like quantifiers or the definite integral sign are second-order.
    \item
        Frege wanted to use this logical framework to establish arithmetic on a
        purely logical foundation. The prevailing view was that the laws of
        arithmetic were synthetic a priori, where you become acquainted by
        arithmetic by experiencing the act of succession. He wanted to reject
        that view and show that the arithmetic truths are analytic. The
        principle he uses to establish this is called Hume's Principle, which
        says that two concepts have the same number just in case there is a
        one-to-one correspondence between the things that fall under them. He
        wanted to avoid postulating the existence of the numbers, but he has to
        go deeper than Hume's Principle in order to avoid this. He wants to be
        able to think of the laws of number as purely logical laws.
    \item
        Something deeper going on was the theory of classes. The motivating
        idea is that if you say Traveler falls into the class of horses, you
        aren't saying anything more or less than just that Traveler is a
        horse. So he wanted to do something like identify 5 with the class of
        all 5-element sets. But he was able to define the numbers so as to
        avoid the circularity.
    \item
        He had a theory of arithmetic based on counting as derivative from
        Hume's Principle, and then he set out on similar project with the real
        numbers. But then he got a letter from Russell, who pointed out
        Russell's Paradox that comes out of the set of sets that aren't members
        of themselves. Frege (basically) gave up the project, but Russell took
        it over. Frege had gotten to this point by saying that for any concept
        there is a corresponding extension. The idea that you could match
        concepts and objects in a one-to-one fashion is exactly what Cantor
        showed you couldn't do with the real numbers. This is a very general
        argument that there are more concepts than extensions. Russel saw that
        and thought that the way to get around this is not to treat numbers as
        objects but rather as second-level concepts. So there is a concept that
        is true of all concepts under which exactly 5 things fall. The former
        concept is what Russell is going to treat as the number 5. Frege got
        into all this trouble by postulating classes, Russell tried to get away
        without classes. Russell wanted to postulate concepts, and he thought
        that you could guarantee the existence of concepts corresponding to the
        predicates of the language on purely logical grounds. Because from
        "Traveler is a horse" we can infer "$\exists x$ $x$ is a horse" we can
        also get "$\exists F$ Traveler is $F$". He thought that would give you
        on purely logical grounds the existence of concepts.
    \item
        But you can still formulate Russell's Paradox by thinking about the
        concept of not falling under itself. Russell wanted to use concepts in
        all the places where Frege used classes, and even though you can still
        get arithmetic from both you can also still formulate the paradox in
        both. He wanted some principle to ensure that the expressions of the
        language are meaningful because he knew that you could take expressions
        that seemed reasonably and get contradictory results. He appealed to
        Poincare's Vicious Circle Principle, because then you can exclude
        notions like a concept applying to itself. Russell's idea was that you
        need to follow Poincare in order to avoid the paradoxes. He added to
        Frege's levels of concepts (the \textbf{type} of the concept, or the
        number of arguments) the \textbf{order} of the concept which pertains
        to which types of concepts are necessarily for formulating that
        concept. Later, he would replace concepts with propositional functions,
        which are functions that take an object as an argument and gives a
        proposition as its result.
    \item
        The Vicious Circle Principle gets in Russell's way. First, we want to
        be able to state the LUB principle of the real numbers. In terms of the
        vicious circle principle, you have this collection $S$ that is bounded
        above, so you have a collection of upper bounds of $S$ and the least
        member of that collection is the LUB of $S$, which violates the vicious
        circle principle. There's another example of violating the VCP with
        trying to define the natural numbers. To get $\mathbb{N}$, he needs to
        postulate the existence of an infinite set of individuals. Zermelo's
        theory was neutral in that it allowed individuals but didn't require
        individuals. Russell had to require the existence of infinitely many
        individuals, which already was a problem because General Relatively
        says that the universe is finite and QM says that at the level of the
        very small we can get indivisible pieces, so it was actually a question
        of whether there are infinite individuals (at least, the postulate is
        contingent and dubious). If you suppose there is a simply infinite set,
        then you show this by showing a one-to-one function whose range is a
        proper set of the domain and then generating a simply infinite set by
        taking something that is in the range but not in the domain and then
        following that cycle. Russell tried to use the axiom of infinity to get
        0 and the successor operation from this simply infinite set. The
        natural numbers can't just be a set with 0 and everything accessible
        with successor -- you need to be talking about the \textit{smallest}
        collection that containes 0 and closed under successor or else you
        don't get induction. But what is meant by "smallest"? The intersection
        of all collections with 0 and closed under successor. But then you are
        defining the natural numbers as the intersection of all collections
        that contain the natural numbers and your definition is circular. 
\end{itemize}

\section{Wednesday, March 8, 2017}

\subsection{Iterating on the Theory of Types}

\begin{itemize}
    \itemsep0em 
    \item 
        Last time, we ended with a discussion on how Russell's theory of types
        is inadequate for doing basic mathematics (you can't get the real or
        rational numbers).The problem was that the viciuos circle principle was
        too restrictive and issues arose with only being able to define
        propositional functions on lower-order/type functions. As a patch,
        Whitehead and Russell proposed that for any propositional function
        there is a coextensive propositional function with the same type and
        lowest possible order (without talking about anything that isn't in the
        extension of the propositional function). This gave them the
        mathematics they wanted but completely gave up the possibility of
        mathematics being pure logic. As long as all the propositions you
        needed could come just from existential instantiation, then it seems
        that you could just use pure logic. But existential instantiation does
        not get you lower-order correlates of the propositional function.
        Assuming the axiom of reduciability, they really gave up the idea of
        reducing mathematics to logic (and admitted as much).
    \item
       It's pretty similar with the axiom of choice, that if you have a set of
       non-empty overlapping set there's another set that picks one element
       from each of them. To Vann, it seems very obvious if you're thinking
       about classes as collections (you can always form the product space and
       find a projection). If you're thinking not in terms of classes but in
       terms of propositional functions and classes as things that we construct
       by constructing predicates, then there's not really intuitive grounds
       for axiom of choice. If you have infinitely pairs of socks, then there's
       no reason you should be able to form a predicate of only one from each
       pair (??). If you think of sets as being created by some form of mental
       process, then the axiom of choice seems dubious.
    \item
        The Banach-Tarski paradox says that you can cut up a sphere of diameter
        1 into pieces and re-assemble the pieces into two spheres of length 1.
        You need the axiom of choice in order to create the cut. Some people
        thin kit's a problem and other's don't. Why it seems like a problem is
        that you get 8x as much matter for free (it seems). Others say that it
        just seems like a problem because we expect volumes to be preserved,
        but if you think of how volume is defined (you get volume of a sphere
        by inscribing polyhedra inside and outside the square and taking the
        limit of many faces), but you can never really close the gap between
        the inside/outside and the sphere. 
    \item
        Russell had two motives for adopting the vicious circle principle: he
        wanted to respond to the set-theoretic paradoxes and he watned to
        respond to the semantic paradoxes. In the introduction to
        \textit{Principia Mathematica} there is some talk about the semantic
        paradoxes. Ramsey proposed that we distinguish between the semantic
        (epistemic) paradoxes from the set-theoretic paradoxes. For the
        purposes of creating a foundation of mathematics you just focus on the
        set-theoretic paradoxes. Then you realize that you don't need the
        vicious circle principle to solve the set-theoretic paradoxes when you
        have the axiom of reducibility. Ramsey suggested that you scrap order
        altogether and just arrange the propositional functions so that a
        function just has to be a higher type than its arguments. Quine took
        that a step further: Frege wanted to talk about classes, Russell wanted
        to replace that with talk of propositional functions. Quine noticed
        that the talk of propositional functions was intended for the logical
        reduction project, but since that failed we might as well go back to
        talking about classes. So we had individuals, classes of individuals,
        relations (binary/ternary/so on) between individuals, binary relations
        relating classes to classes, individuals to classes, etc. So you end up
        with this structure that is still kid of complicated but still much
        simpler than Russell's solution.
    \item
        Norbert Weiner saw that even that picture could be simplified by
        instead of talking about relations, let's identify a relation with a
        class of ordered pairs/triples/etc. (identify $<a, b, c>$ with $<a, <b,
        c>>$. So you can just talk about individuals, classes of individuals,
        classes of classes of individuals, etc. Weiner's idea was that you
        didn't have to treat ordered pairs as primitive. The law of ordered
        pairs says that $<a, b> = <c, d>$ iff $a = c$ and $b = d$. Norbert
        noticed that you could take $\{\{\{a\}, \emptyset\} , \{\{b\}\}\}$, and
        you can verify that this satisfies the law of rodered pairs. There are
        more brackets than you'd think because he was working in the theory of
        types and need to be working with things of the same type. With this
        simplication, what started as a monstrously complicated system becomes
        very simple.
    \item
        To get mathematics, he needed infinitely many individuals. If you have
        only finitely many individuals, no matter how high up the hierarchy he
        went you'd still only have finitely many things. But if the individuals
        about which you're talking are physical objects than it is actually
        pretty dubious that are infinitely many. So they added the Axiom of
        Infinity and they didn't regard it as obviously true.
    \item
        There's still one feature of that project that is still kind of
        anomalous. You want to say that there are 8 people in the room, and how
        we're going to make sense of that is by saying that the number 8 is the
        collection of all 8-element classes of individuals. So a number is a
        class of classes of individuals such that every class of individuals
        that can be put in one-to-one correspondence with a member of the class
        is a member of the class. What is still peculiar about this theory of
        types is that you can't mix types which means you can't use the same
        numbers to count individuals as to count classes of individuals. So
        there's a different number system of each type and there are infinitely
        many systems of natural numbers. It's not fatal, but it's just a little
        fussy and seems kind of artificial. 
    \item
        G\"odel stepped in a suggested that there is no good reason not to make
        the classes cumulative instead of only allowing members of type $n - 1$
        in classes of type $n$. Originally, we wanted this hierarchy of classes
        in order to protect us from the paradoxes and the vicious circle
        principle, but we've given up the vicious circle principle. He noticed
        that we get the paradoxes when we ask whether a member of the class is
        at the same type as the class, and so we can lighten the restriction to
        allowing any type below the class, not just the one type just below it.
        Originally, we get the type hierarchy from a grammatical restriction on
        concepts/objects, but once you allow cumulative classes you need to
        abandon the grammatical distinction - so you say that you won't make
        type distinctions among the things we're talking about as far as logic
        is concerned.  Some of the things we will talk about are individuals,
        sets of individuals, and so forth, but we're going to be able to talk
        about those all at once without distinguishing between them (there's
        only one kind of variable for the logic). What gets us the hierarchical
        structure is not a grammatical restrictuion but rather an axiom that
        tells us that the sets are well-founded. so in G\"odel's system you
        have a very simple logic (first-order predicate calculus) but you have
        a lot of not simple axioms guaranteeing the existence of sets. 
    \item
        So it looks as if there is no hope for reducing mathematics to logic,
        it looks like Cantor and Dedekind won. The advantages of a logical
        conception of set over a combinatorial conception of set disappear once
        this project doesn't work. And ZF set theory is so much more powerful
        because it can extend into the transfinite. But this is also possibly
        bad because it can make it more vulnerable to contradiction. Still
        there are lot more points that have gone to the combinatorial
        conception rather than the logical conception. There is still a lot to
        be desired and it's a big loss to have mathematics be synthetic a
        priori rather than analytic. 
    \item
        G\"odel's incompleteness theorem throws a wrench in the works by
        showing that there are arithmetic truths that we can recognize as true
        that aren't derivable from the axioms, and that even if you add more
        axioms there are still more truths that aren't provable.
    \item
        More recently, the Neologicist program has been trying not to get us
        all of ZFC but rather to get us mathematics strong enough in order to
        serve or purposes will staying in an (arguably) logical framework.
    \item
        Dedekind proved that arithmetic is categorical, but if you think of
        arithmetic as a first-order theory the way we do know, then that is not
        categorical (it is not a second-order theory). You get induction from a
        quantification over properties and you get categoricity from induction.
        But when you do things in a first-order framework you have an axiom
        schema for induction and so you have infinitely many induction axioms
        instead of a single second-order axiom. But then this new set of axioms
        isn't categorical and by G\"odel's work isn't complete. 
    \item
        The next part of our story is going to be a revival of second-order
        logic as something we can do in teh context of modern mathematics when
        we're well beyond the \textit{Principia} stage. That revival is due to
        George Boolos. Next time, we'll talk about Boolos and Quine and then
        we'll start talking about Benacerraf. Read Quine and Boolos articles.

\end{itemize}

\end{document}

