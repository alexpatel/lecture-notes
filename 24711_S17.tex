\documentclass[12pt]{article}
\usepackage{latexsym}
\usepackage{amssymb,amsmath}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage[margin=1.0in]{geometry}
\allowdisplaybreaks

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{cor}{Corollary}
\newtheorem{lemma}[theorem]{Lemma}

\usepackage[T1]{fontenc}
\usepackage{ccfonts}
\setlength\parindent{0pt}

\renewcommand{\labelenumi}{\thesection.\arabic{enumi}}
\renewcommand{\labelenumii}{\thesection.\arabic{enumi}}
\renewcommand{\labelenumiii}{\thesection.\arabic{enumi}}

\begin{document}

\begin{center}
\textbf{24.711: Topics in Philosophical Logic} \\
Alexander H. Patel \\
{\tt alexanderpatel@college.harvard.edu} \\
Last Updated: \today
\end{center}

These are lecture notes for the Spring 2017 offering of MIT 24.711: Topics in
Philosophical Logic. Pardon any mistakes or typos.

\tableofcontents

\section{February 15, 2017: Zeno's Paradox of the Arrow}

\begin{enumerate}
    \itemsep0em 
    \item  An object is at rest during an interval iff it occupies only a
        single position during that interval (not during a moment of time).
        It's stationary during an instant only if the instant is contained in
        an interval during which it's at rest. 
    \item Ancient Greeks could only answer the question qualitatively because
        they couldn't measure time (although they could measure distances). Use
        a compass to make circles and form multiples of a unit length on a
        line.
    \item Can use a straight edge and compass to get an estimate of length to
        any precision up to a rational number, but no further.
    \item Aristotelian physics gives no good way of measuring a length of time.
        Earth, air, wind, fire all have natural motion (up, down), but because
        of acceleration you can't figure out good lengths of time - you need
        something that moves at a uniform speed. The natural motion of things
        in the heavens is circular, so you can use star movement to measure
        lengths of time (not as simple as one would think because Aristotle's
        system was geocentric where the planets orbited in a circle about the
        earth).
    \item
        Need to be able to measure time and distance in order to measure speed
        and so to get close to a solution for the core question of what it
        means to be stationary.
    \item
        Galileo look at pendulum movement - he saw a smooth continuous movement
        that happens at intervals (PE being converted into KE). The
        Aristotelian saw chaotic movement in the pendulum (you are displacing
        the bob and it's swinging is it trying to go downward but being
        contained by the string). Aristotle didn't have the principle of
        balancing of forces on the bob. Aristotle's answer to the question of
        why the bob doesn't stop is that there is some nonsense with a vacuum
        of air being generated behind the bob and pushing it forward. We can
        measure time by dividing the length of the pendulum rod and noting the
        period is inversely related to the square of the length of the rod.
    \item
        Speed during an interval is the quotient of change of distance over
        change and time. Zeno gave us the idea of 0 speed over an interval, now
        we have a quantitative idea of non-zero speed during an interval. But
        we still have to account for the idea that the ball is at rest only at
        its apogee but at no other point in its path.
    \item 
        We can solve the ball problem by solving $x'(t) = 0$, where $x'$ is the
        limit of the difference quotient of $(x(t + h) - x(t))/h$. Aristotle
        thought that bodies were the only things that were real and that bodies
        aren't made up of points or surfaces. So we can't just think of the
        ball but also need to consider the position in spacetime of the ball -
        we need to think of the trajectory (potential positions occupied by the
        ball) as existent, even when the ball isn't there. But Aristotle argued
        that a line isn't made up of points so this doesn't play out well under
        Aristotelian physics - i.e. we can talk about velocities but not of
        instantaneous velocities.
    \item 
        Why does Aristotle preclude the solution of taking the derivative? Do
        we not just take the limit over smaller and smaller intervals about the
        instant? The Aristotelian post-Newton understood the limit as the
        continual dividing of the line into smaller pieces.
    \item
        Things change when we switch to dynamics - throw a ball up at some
        initial speed and the downward force of gravity will decelerate the
        ball until it reaches 0. But since acceleration is $dv/dt$ there's no
        good way to define instantaneous acceleration out of velocity, which is
        also a function.
    \item
        You know there are times when the ball is going up and times when the
        ball is going down. We want to say there is a time when the ball
        reaches its highest point when its velocity was 0, how do we know there
        was such a time? We could solve this with the IVT but we want to do
        this constructively by constructing the cut between positive velocities
        and negative velocities. Can we get the LUB principle from numbers just
        from the movement of the ball? If the LUB principle didn't hold for the
        numbers then there would points in the ball's flight where it didn't
        have any associated number for its height.
    \item 
        Most of what we can use real numbers for (measurements of things) we
        can get away with just rational numbers. Dedekind had originally the
        bad idea that we could get away with just rational numbers, but that
        was thrown out with $\sqrt{2}$ and the Ancients. Also need cube roots
        to deal with the roots of cubic polynomials. So the real numbers fall
        out of solving polynomials with rational coefficients - but this
        doesn't solve the ball problem because you have no reason to believe
        that the place where the ball is stationary is the root of an equation.
    \item 
        The Ancients don't allow for the idea that there is a point on a line
        that is defined by the all the points to the right of it or to the left
        of it. For the ball, there needs to be a top point to define the switch
        of signs.
    \item
        Is it true that there is a supremum of all the points achieved by the
        ball? Is the ball at rest at this point? What if the ball only achieves
        heights of rational numbers (so it skips between points) or if the ball
        has a hole at the maximum of its height curve?
    \item
        From Mathematica, you have a tire on a hubcap that each go through the
        same number of rotations - how does the hubcap not move much less
        distance than the tire? Galileo: the tire is just a polygon, the hubcap
        goes through places where there is no corner of the polygon
        instantaneously which is just a wacky idea.
    \item 
        Conclusion: you can't explain what is going on if you just think in
        terms of bodies and don't think about space and lines as being made up
        of points.
    \item
        An alternative view says that only bodies are real, and the bodies can
        be in different places but the places aren't real, just the bodies are
        (and the distance relations they have with each other). Kant disputed
        this view - if God made a single marble hand before anything else, then
        He could've made either a right hand or a left hand (it has to be one
        or the other), but if all we have is bodies with spatial relations then
        there is nothing different between a right hand and a left hand; but
        there is a difference between right hand and left hand so there has to
        be something to account for the difference - you need position.
\end{enumerate}

\section{February 21, 2017: Dedekind's Construction of $\mathbb{R}$}

\begin{enumerate}
    \itemsep0em 
    \item  
        Jill starts at the bottom of a hill when Jack starts and the top and
        the reach the top/bottom at the same time. Is there a point where they
        are at the same elevation? Yes - take the set of all times when the
        difference in height was positive and then take the least upper bound.
        Most people say that it comes from their motion being continuous.
    \item
        Really early on people learned how to use numbers to measure things -
        at least from having to re-establish property lines after the flooding
        of the Nile. This entailed measurement by yardstick which always yield
        results in fractional form. But can we get these same numerical
        properties without actually deferring to the use of numbers? 
    \item
        The rationals as fractions seem very well understood - the gaps between
        them were less well understood. We know that all the rationals along
        the path will be reached by the ball - how can we justify whether there
        are non-rational points that are hit by the ball.
    \item
        Pythagoreans found that simple ratios of where you put your finger on
        the lyre string correspond to harmonic sounds, but then one of them
        discovered that there are lengths that aren't rationals. He
        didn't find it out by measurement but rather by reductio ad absurdum -
        finding the length of the diagonal of the square with side length 1. He
        showed that it can't be rational (and was thrown overboard for his
        discovery). So you have to have square roots if you want to do geometry
        like the Greeks (because of conic sections).
    \item
        There's a problem which is for any square find another square that has
        twice the area - it was known by Plato and was in the Meno - solve it
        by taking the diagonal of the first as the side length of the second.
        Can you do this with a cube? You can't do this with a compass and
        straight edge. The medieval Arabics pushed forward by going passed
        compass/straightedge and finding the roots of a cubic equation without
        requiring that the length we're talking about can be one you can
        actually create with a compass and straightedge. That produced a whole
        new family of lengths never talked about by the Greeks. It was widely
        believed that you could create new numbers by constructing equations
        with irrational roots with only rational coefficients. For example $x^3
        = 2$ you would introduce $\sqrt[3]{2}$. It was widely thought that all
        the real numbers were got by solving such equations, but for example
        $\pi$ isn't.
    \item
        Cantor showed that there are many more real numbers that aren't
        solutions to equations than ones there are. The question at the end of
        the 19th century was how to get a picture of what the real line was
        like - how to fill in all the holes. Dedekind's answer was to introduce
        the cuts. To fill in all the gaps, we need a cut everywhere. He gave a
        criteria for what it would mean for $\mathbb{R}$ to be complete, and
        second to show that there really was such a thing as that complete
        system of real numbers. The algebraic properties of the real numbers
        are relatively easy to satisfy, and you need added properties in order
        to fill in all the gaps. The principle Dedekind proposed was the
        least-upper bound principle. He also wanted to convince people that
        this was final - that you couldn't go any further.
    \item
        Dedekind started by seeing if a geometric approach would suffice - he
        thought this was obvious - why? You also need a lot of (controversial)
        set theory to get Dedekind cuts, but the Dedekind cuts do reduce the
        reals to the rationals to the integers. Around this time, everyone
        considered the laws of geometry to be synthetic a priori (Kant), where
        we could only make sense of our sensory experience if we organized them
        into three-dimensional space. It seems dubious that the way we organize
        space should be the foundation of analysis because we have tons of
        applications of the real numbers that have nothing to do with space.
        Also, there's non-Euclidean geometry.
    \item
        Dedekind started by enumerating the rules needed for $\mathbb{R}$:
        field axioms, ordering, etc. But that doesn't distinguish from the
        rationals. You need something more: the completeness principle (LUB).
        Dedekind gives some axioms that the thought could answer the question
        of what the real numbers are, or at least he says the real numbers
        satisfy those structural features. Why is identifying the structural
        features enough to say that you've identified the real numbers? There
        are going to be lots of other algebraic systems that satisfy those
        axioms. You have to also give the intended model for those axioms. The
        physical line satisfies those axioms, but we have no reason to believe
        that any particular one is not the real number system. Also any
        complete model of those axioms is going to be isomorphic to any other.
        Why is giving the structure not enough?
    \item
        At the same time, Frege was investigating the foundations of
        arithmetic. He thought that the only principle he needed was Hume's
        Principle (two collections have the same elements iff there's a
        one-to-one correspondence between the elements). He showed you could
        get PA axioms from Hume's Principle, but he still asked: how do I know
        whether Julius Ceasar is a number? We expect a numeral to pick out a
        definite thing, but we can never do this with only axioms. Dedekind
        introduced the idea that the numerals don't have to stand for definite
        objects - that mathematics is rather about identifying structural
        properties, and that identifying the structure is all you can and need
        to do. 
\end{enumerate}

\section{February 22, 2017: Dedekind's Construction of $\mathbb{R}$}

\begin{enumerate}
    \item
        Dedekind asked: what further properties than the normal ordering and
        field properties are necessary to specify the real numbers?
        Completeness. His proposal is to create cuts of the rationals into two
        non-empty classes so that everything in the lower portion is less than
        everything in the upper portion. Completeness means that anytime you
        have such a cut there is a real number defining it. This principle
        amounts to the least-upper bound principle. He showed that this
        condition characterizes the real number system (up to isomorphism).
        Historically, people had made systems that purported to be the real
        numbers but it turned out that they left some numbers out. But Dedekind
        showed that you can't add anything to his system and get anything
        that's properly larger. 
    \item
        The isomorphism theorem says that if you have any two models of his
        axioms $a$ and $b$, you first define the positive integers of $a$ to be
        those that contain $0 \in a$ and are closed under succession (and
        define the positive integers of $b$ the same way), and then define a
        map between the two sets of natural numbers. This map is injective - if
        it weren't, then the set of integers that had mappings would have a LUB
        $b'$, and somewhere between $b'$ and $b' - 1$ you would have an integer
        that gets mapped. This lets you map the rationals of $a$ to the
        rationals of $b$, and so then we get an isomorphism of Dedekind cuts
        and so of the real numbers in $a$ and $b$. 
    \item
        So we've completely characterized the structure we're looking for - how
        do we know that there is something that exhibits that structure?
        Dedekind's response is to define the set of all cuts to be the real
        numbers and then show that this structure satisfies the axioms. So he
        takes the construction to be a sufficient answer to the question of
        what the real numbers are. But it feels like he's just given us
        something that is isomorphic to the real numbers. 
    \item
        Frege equivalently gives structural axioms for the natural numbers, but
        wasn't satisfied because he couldn't answer the question of whether
        Julius Caesar was a natural number. Hume's Principle is a structural
        property that only characterizes the natural numbers up to isomorphism.
    \item
        All we need to construct the natural numbers is an infinite set from
        which we can generate a simply infinite set, but that's non-trivial
        because, starting from Zeno's Paradox, there is a long line of people
        saying that we can't have an infinite set, just a potentially infinite
        set. They say that all we can do is give methods for taking a finite
        sequence and extending it, but the idea that we can treat an infinite
        set as a whole was long treated as contradictory. Dedekind thinks he
        can build an infinite set by taking the totality of objects of his
        thought and take a member of that totality S and form the thought "S is
        an object of one's thought", and then recursively do that. That's a
        one-to-one function from the objects of one's thought to the objects of
        one's though, but it isn't onto because one's ego isn't of the form "X
        is the object of my thought". This skirts the question of potentially
        vs. actually infinite because the totality of objects of thought is
        something given to you, not something constructed.
    \item 
        He says that the natural numbers are a "free created of the human mind"
        which he clarifies as being because they are a result of the process of
        abstraction specified above. This isn't completely new - Cantor does
        something similar when he wants to go beyond the natural numbers into
        the transfinite by looking at the different ways of ordering the
        collection and then defining an order isomorphism and then defining the
        order types as got from the orderings by the process of abstraction.
        You regard two orderings the same if their orderings are isomorphic
        (there's a bijection from one to the other that preserves the order).
        Or you can go even more abstract and say that two totalities are the
        same if there is a bijection between them, irrespective of ordering.
        That gives you the cardinal numbers. Aristotle also gets the objects of
        geometry similarly - he thought of them as ordinary solid bodies but we
        abstract away all the non-geometrical properties. Both Cantor and
        Dedekind were dipping into that tradition.
    \item
        In retrospect, it seems like this is a big transition from thinking of
        mathematical terms like "natural/real/complex number" as denoting
        definite things (not things known from sense-experience, but still
        definite entities) to thinking about them as if we can talk about them
        as definite things once we've characterized them up to isomorphism.
        Modern mathematicians are pretty much invariably subscribers to the
        latter view - you talk about mathematical objects, but mathematical
        objects are what they are because of their properties and properties
        only characterize up to isomorphism. There was a change in the way
        mathematicians talked about mathematical objects that philosophy was
        really slow to notice.
    \item
        Cantor also had a way of creating the real numbers out of the
        rationals. Cantor himself was interested in Fourier Series and when
        they converge, for him the idea that the real numbers were complete was
        cashed out by the idea that series converge whenever it's possible for
        them to converge. For any convergent sequence, we have $\forall k,
        \exists N$ such that $n > N \Rightarrow |a_n - a_N| < \frac{1}{k}$
        (Cauchy sequence). So one criterion for the completeness of the real
        numbers other than the LUB principle is the Cauchy criterion implies
        convergence for any sequence. You can derive one criterion from the
        other. Cantor then defined the equivalence relation between $\{x_n\}$
        and $\{y_n\}$ as for any $k$ there is a sequence term such that $y_n$
        and $x_n$ are arbitrarily close passed the sequence term. You can show
        that Dedekind's and Cantor's principles yield isomorphic copies of the
        real numbers. But the question never arose as to which of these is the
        genuine construction of the real numbers. It didn't occur to them to
        ask: what's a real number - a Dedekind cut or an equivalence class of
        Cauchy sequences?
    \item
        Hilbert's axiomitization of geometry: he gave the set of axioms and
        wasn't initially concerned with the question of whether the system was
        complete. We know we get a model of the geometry axioms if you take a
        point to be an ordered triple of real numbers (identify a point with
        its coordinate in $\mathbb{R}^3$, which doesn't have anything to do
        with space and yet is still a perfectly good model). You also get a
        perfectly good model if you identify a point with an ordered triple of
        algebraic numbers - so the geometric axioms do not require
        completeness. Later on, Hilbert started to worry about completeness and
        so he added an axiom in the 9th edition so that the new axiom system is
        complete. One of the axioms of the original system was the Archimedean
        axiom: you can construct a line segment out of a sub-segment so that
        there is some multiple of the sub-segment that will surpass the end of
        the larger segment. Traditionally, geometric axioms were supposed to
        represent three-dimensional space, but Hilbert rather didn't deny that
        the axioms describe physical space but didn't assume that they were
        about physical space. He said the axioms were about systems that
        satisfy those axioms, and nothing more - there's nothing more to being
        an intended model for the geometric axioms. This is similar to group
        theory - there's no intended model for group theory other than a system
        that satisfies those axioms. This is a real departure from the idea
        that mathematics has a definite subject matter.
    \item
        You can have a name without a referent - for example, "Cerberus" or
        other names that occur within myths. You don't have that with names
        like "Cherry" - there's a definite referent to the name "Cherry". But
        we have these numerals in mathematics (e.g. $\sqrt{2}$) that don't have
        a uniquely determined thing that they refer to. The issue with idea of
        identifying the square root of 2 with the set of all things that when
        squared is 2 is problematic because you can't square a set. And you
        can't identify it with any one object whose square is two for similar
        reasons. There's a worry that Dedekind gave us a construction of what
        he called the real numbers and long before him the Egyptians were using
        numerals that purported to be real numbers, so did the Ancient
        Egyptians refer to a Dedekind cut when they wrote down one such
        numeral? Or, possibly, could the real number signs not refer to
        entities but instead to some action, like the act of taking the
        successor with the natural numbers? Well, the numerals do correspond in
        an objective way similarly to how people's names objectively refer to
        people. If it were purely made up, then there wouldn't be a "correct"
        answer for question with real-numbered answers.
    \item
        Dedekind described what he was doing as the reduction of analysis to
        arithmetic, which was understood to have secure foundations. But
        analysis has less secure foundations because people didn't have a clear
        understanding of continuity and limits and what was required for a
        sequence to converge - there was just a general lack of clarity. It's
        more accurate to say that he reduced analysis to set theory or set
        theory plus arithmetic because what he needs to form the cuts is a lot
        of set theory. Looking back, it seems that he really did do something
        important for our understanding of the foundations of analysis, but it
        was not reducing analysis to arithmetic but rather constructing
        analysis within this theory of sets. Next time let's look at the
        axiomatic theory of sets and consider Dedekind's construction as a
        construction of the real numbers within set theory.

\end{enumerate}

\section{March 1, 2017: Combinatorial Conception of Sets}

\begin{enumerate}
    \itemsep0em 
    \item
        Last time we talked about Zermelo's axiom of set theory. One thing
        Zermelo wasn't addressing but were in the background were the
        paradoxes, which is why people responded to his proof of the
        well-ordering theorem with such uncertainty (their understanding of how
        sets work was shaken by the appearance of paradoxes). Formal set theory
        was still pretty new and their study only came to the foreground with
        Dedekind and Cantor and it seemed to fall immediately into
        contradiction.
    \item
        The most prominent of paradoxes was Russell's paradox - some sets are
        elements of themselves, so consider the set of sets that are not
        members of themselves. If you ask the question of whether that set is a
        member of itself, you get a contradiction. The paradox has a direct
        analogue about language - "dog" isn't a dog so it doesn't apply to
        itself, but the phrase "does not apply to itself" applies to itself iff
        it doesn't.
    \item
        Another paradox was with Cantor's study of ordinal numbers, he found
        that the ordinals were well ordered and for any well ordered set there
        is an ordinal that describes the order type of that set. Any ordinal is
        the order type of the ordinals less than it. But consider the
        collection of all ordinals, which is well ordered, and so there is a
        map from all the ordinals to all the ordinals less than some ordinal.
        Keep applying the map and then you get an infinite descending sequence
        which is a contradiction because the ordinals are supposedly well
        ordered. The semantic analogue is to take all the names of ordinals,
        there are only countably many names and so there are only countable
        many names of ordinals, but since there are uncountably many ordinals
        there are ordinals that aren't named. Since the ordinals are
        well-ordered there is some least ordinal is not named, but we have just
        specified a name for it. Also there is a least natural number nameable
        in fewer than 19 syllables. 
    \item
        Cantor showed that there are uncountably many real numbers by assuming
        that there are only countably many real numbers and then disproving the
        bijection by constructing a new real number not in the enumerated set.
        You can make a bijection $\mathbb{R} \rightarrow \{q_1, q_2, q_3,
        \ldots \in \mathbb{Q}\}$. He generalized the result to show that for
        any set there are more subsets of $S$ than the number of elements of
        $S$. But then take the set of all sets, the cardinal number of the
        power set of the set is larger than the cardinal number of the set
        itself. But the power set of all sets of sets is included in the set of
        all sets and so the cardinal number of the power set is less than or
        equal to the cardinal number of the set of all sets. There is no direct
        linguistic analogue but it came from the generalization of Cantor's
        real number uncountability proof. If we look at that theorem
        linguistically, we see that there are only countably many names for the
        uncountable $\mathbb{R}$, and then put the names in a list an use
        Cantor's procedure to construct a real number that is nameable but not
        on the list of all possible names.
    \item
        Cantor just rejected that there was such thing as the set of all sets.
        He thought there were theological implications. He wrote to the Pope
        (no response) and said that he was developing a theory of the actual
        infinite but there may be worries because the church teaches that only
        God is infinite. He says it isn't blasphemous because he says he has
        found an intermediate level between the finite and the absolutely
        infinite (transfinite) where the transfinite goes beyond what we
        ordinarily think of the finite, but it's not complete limitless. If you
        had something completely limitless then you can't number it or
        comprehend it mathematically - only God is at the level of the
        absolutely infinite which is above not just the finite but also the
        transfinite. So Cantor's work isn't bringing God down to the level of
        ordinary mathematicians, but rather he boosted God up to a level
        farther beyond the level of things that Earthly things are. 
    \item
        So there's these analogues between set theoretic paradoxes and semantic
        paradoxes. Zermelo didn't seem interested in the semantic part. Russell
        had the exact opposite attitude - he thought this showed a deep
        discontinuity in human thought, one that was so profound because it
        manifested in a lot of different ways. How important is it to get a
        unified solution to the set of two paradoxes? It really seems like they
        are the same phenomenon. 
    \item
        This week we're going to look at a paradox that wasn't among the list of
        Russell's paradoxes - developed around 1960. You can't recursively pick
        sets as elements of other sets - there's no infinite descending chain.
        Say a set is well-founded if there aren't any infinite descending
        chains beginning with. Let $W$ be the set of all well-founded sets. If
        there were an infinite descending chain ending with $W$ then look at
        the chain the ends at the element which is an element of $W$ and so
        that chain is infinite and the element is not well-founded. So $W$ has
        to be well-founded. But then $W \in W$ and so there's an infinite chain
        ending at $W$ by picking $W$ for every link of the chain. Since no
        well-founded set is a member of itself, this paradox seems to reduce
        straight to Russell's Paradox. But it doesn't because you could have $A
        \in B \in A \in B \in \dots$. So no loops of any length around whereas
        Russell's paradox is just a loop of length one. This paradox turned
        people's attention to sets that are well-founded - but most sets that
        are useful for math are those that are well-founded. If you want to
        really think closely about set theory but your interest in set theory
        is just for finding a theory of sets that is useful for mathematics,
        then you can just stick with the well-founded sets.
    \item
        So there was an axiom proposed that said that all sets are
        well-founded. What amounts to the same thing is: for any non-empty set
        $S$, there is an element $s \in S$ such that $\forall t \in s, t \notin
        S$. Originally it was just adopted for convenience but it does yield a
        really pretty picture for what the universe of sets looks like. If we
        assume that the things that aren't sets form a set, then you get this
        picture of the theory of types. The crucial axiom for building out this
        structure is the axiom of ordered pairs - this allows you to put
        together two elements from different levels. This is the way that
        Zermelo was thinking about it but not the way that Russell and
        Whitehead were thinking about it. Cantor's paradox entails forming a
        set at some particular level, but the set of all sets must be at a
        level before which the set of all sets is formed and so there is no
        level where the set of all sets is at. Since a set is always formed at
        a level after the level at which its elements are formed, so you solve
        the same set of paradoxes. For the ordinals, each level of the
        hierarchy introduces a new ordinal. Each level of the hierarchy
        introduces exactly one new ordinal. So in order to get the collection
        of all the ordinals it would have to be formed at a stage after which
        you'd already gotten all the ordinals and so there is no collection of
        all the ordinals. So there's a response to all the set-theoretic
        paradoxes that comes just from trying to form a set that violates the
        foundation axiom. 
    \item
        So adding another axiom gave us the stronger system because it removes
        an inconsistency but does not introduce one. If you restrict the axioms
        of set theory to range only over well-founded sets. You can verify that
        each formula you get from an axiom of set theory by restricting the
        quantifier is a theorem of set theory. If you could derive a
        contradiction from the axioms of set theory including the axiom of
        foundation then you could get a contradiction in ZFC.
    \item
        The tradition, beginning with Cantor, is thinking about collections
        formed from contained elements and you need collections to be
        well-founded and so you get paradoxes if you don't restrict to
        well-founded collections. The opposite view is from Frege where you get
        sets by starting with concepts. Von Neumann thought that you get
        contradictions when you start forming sets that are really large ($>>>
        \mathbb{R}$) like the set of all the ordinals or the set of all the
        cardinals, etc. So forming sets that are way too big is impossible but
        formulating sets that are relatively small is okay. The range of a
        function on a set will be at most the same size as the domain set so
        then if the things in the domain aren't too many to form a set then the
        things in the range aren't too many to form a set, either. VN had the
        replacement principle and this more global principle that you can form
        sets unless they are too big, "too big" meaning things form a set
        unless those things are equinumerous with the entire universe. So if
        you have set that's so big that if it's a set then the entire universe
        is a set then that set is not actually a set. So there's a different
        way of thinking about where the paradoxes come from by having sets that
        are just too big. Axel took this idea and build a whole set theory out
        of it. 
    \item
        This is the combinatorial conception of sets as collections. Next time
        we will think about sets from a logical point of view by starting with
        concepts and then get to sets by a process of abstraction.
\end{enumerate}

\section{March 6, 2017: Logical Conception of Sets}

\begin{enumerate}
    \itemsep0em 
    \item
        We've been talking about set theory, of which there are two
        conceptions. The combinatorial approach says that sets are collections
        built up from individual. The other idea is the logical conception of
        sets, where you gets sets by starting with concepts and forming sets by
        abstraction. This conception starts with Frege. Frege started out by
        looking at complex names like "the capital of France" and saw that the
        name was formed by "France" and the function sign "the capital of \_".
        "France" names something, but "the capital of" only becomes complete by
        begin supplanted by a name. Concepts are unsaturated and are not
        individuals because it needs another object to be completed. 
    \item
        We know what an incomplete building - there are still bricks and
        mortar, but just not enough to yield a whole. But what is it for a
        concept to be essentially incomplete? At the syntax level, you put a
        name into a concept-phrase; at the semantic level, you put an object
        into a concept to get a truth value. Someone might (incorrectly) think
        that Versailles was the capital of France and say "We're going to Paris
        and then going to the capital of France". But you can't substitute
        "Paris" for the latter reference because the person believes that the
        referent of "the capital of France" is Versailles. Senses deal with
        things like this (i.e. belief contexts). Thinking about sentences as
        having the True/the False as their referents turned out to be very
        fruitful because he could think as predicates as functions. This
        allowed standard operations with functions from basic algebra to be
        applied to concepts.
    \item
        Frege has individuals, functions, function signs with more than one
        argument, and second-level functions. Second-level functions: "someone
        is a wise philosopher" has a similar grammatical structure as "Socrates
        is a wise philosopher", so it looks like you have "\_ is a wise
        philosopher" as a concept which can take "Socrates" and "someone" as
        arguments. But in the latter case the individual about which you're
        talking is only indefinitely specified. Frege saw that this wouldn't
        work because of things like "Someone is wise" and "Someone is a
        philosopher" does not yield "Someone is a wise philosopher" and so the
        logical structure of the two is really quite different. Frege's idea is
        that "someone" is not a name, but rather a function sign that takes as
        its argument a concept. So "someone" is the property that a property
        has if there is at least one person who falls under ther latter. So
        things like quantifiers or the definite integral sign are second-order.
    \item
        Frege wanted to use this logical framework to establish arithmetic on a
        purely logical foundation. The prevailing view was that the laws of
        arithmetic were synthetic a priori, where you become acquainted by
        arithmetic by experiencing the act of succession. He wanted to reject
        that view and show that the arithmetic truths are analytic. The
        principle he uses to establish this is called Hume's Principle, which
        says that two concepts have the same number just in case there is a
        one-to-one correspondence between the things that fall under them. He
        wanted to avoid postulating the existence of the numbers, but he has to
        go deeper than Hume's Principle in order to avoid this. He wants to be
        able to think of the laws of number as purely logical laws.
    \item
        Something deeper going on was the theory of classes. The motivating
        idea is that if you say Traveler falls into the class of horses, you
        aren't saying anything more or less than just that Traveler is a
        horse. So he wanted to do something like identify 5 with the class of
        all 5-element sets. But he was able to define the numbers so as to
        avoid the circularity.
    \item
        He had a theory of arithmetic based on counting as derivative from
        Hume's Principle, and then he set out on similar project with the real
        numbers. But then he got a letter from Russell, who pointed out
        Russell's Paradox that comes out of the set of sets that aren't members
        of themselves. Frege (basically) gave up the project, but Russell took
        it over. Frege had gotten to this point by saying that for any concept
        there is a corresponding extension. The idea that you could match
        concepts and objects in a one-to-one fashion is exactly what Cantor
        showed you couldn't do with the real numbers. This is a very general
        argument that there are more concepts than extensions. Russel saw that
        and thought that the way to get around this is not to treat numbers as
        objects but rather as second-level concepts. So there is a concept that
        is true of all concepts under which exactly 5 things fall. The former
        concept is what Russell is going to treat as the number 5. Frege got
        into all this trouble by postulating classes, Russell tried to get away
        without classes. Russell wanted to postulate concepts, and he thought
        that you could guarantee the existence of concepts corresponding to the
        predicates of the language on purely logical grounds. Because from
        "Traveler is a horse" we can infer "$\exists x$ $x$ is a horse" we can
        also get "$\exists F$ Traveler is $F$". He thought that would give you
        on purely logical grounds the existence of concepts.
    \item
        But you can still formulate Russell's Paradox by thinking about the
        concept of not falling under itself. Russell wanted to use concepts in
        all the places where Frege used classes, and even though you can still
        get arithmetic from both you can also still formulate the paradox in
        both. He wanted some principle to ensure that the expressions of the
        language are meaningful because he knew that you could take expressions
        that seemed reasonably and get contradictory results. He appealed to
        Poincare's Vicious Circle Principle, because then you can exclude
        notions like a concept applying to itself. Russell's idea was that you
        need to follow Poincare in order to avoid the paradoxes. He added to
        Frege's levels of concepts (the \textbf{type} of the concept, or the
        number of arguments) the \textbf{order} of the concept which pertains
        to which types of concepts are necessarily for formulating that
        concept. Later, he would replace concepts with propositional functions,
        which are functions that take an object as an argument and gives a
        proposition as its result.
    \item
        The Vicious Circle Principle gets in Russell's way. First, we want to
        be able to state the LUB principle of the real numbers. In terms of the
        vicious circle principle, you have this collection $S$ that is bounded
        above, so you have a collection of upper bounds of $S$ and the least
        member of that collection is the LUB of $S$, which violates the vicious
        circle principle. There's another example of violating the VCP with
        trying to define the natural numbers. To get $\mathbb{N}$, he needs to
        postulate the existence of an infinite set of individuals. Zermelo's
        theory was neutral in that it allowed individuals but didn't require
        individuals. Russell had to require the existence of infinitely many
        individuals, which already was a problem because General Relatively
        says that the universe is finite and QM says that at the level of the
        very small we can get indivisible pieces, so it was actually a question
        of whether there are infinite individuals (at least, the postulate is
        contingent and dubious). If you suppose there is a simply infinite set,
        then you show this by showing a one-to-one function whose range is a
        proper set of the domain and then generating a simply infinite set by
        taking something that is in the range but not in the domain and then
        following that cycle. Russell tried to use the axiom of infinity to get
        0 and the successor operation from this simply infinite set. The
        natural numbers can't just be a set with 0 and everything accessible
        with successor -- you need to be talking about the \textit{smallest}
        collection that contains 0 and closed under successor or else you
        don't get induction. But what is meant by "smallest"? The intersection
        of all collections with 0 and closed under successor. But then you are
        defining the natural numbers as the intersection of all collections
        that contain the natural numbers and your definition is circular. 
\end{enumerate}

\section{March 8, 2017: Iterating on the Theory of Types}

\begin{enumerate}
    \itemsep0em 
    \item 
        Last time, we ended with a discussion on how Russell's theory of types
        is inadequate for doing basic mathematics (you can't get the real or
        rational numbers).The problem was that the vicious circle principle was
        too restrictive and issues arose with only being able to define
        propositional functions on lower-order/type functions. As a patch,
        Whitheead and Russell proposed that for any propositional function
        there is a coextensive propositional function with the same type and
        lowest possible order (without talking about anything that isn't in the
        extension of the propositional function). This gave them the
        mathematics they wanted but completely gave up the possibility of
        mathematics being pure logic. As long as all the propositions you
        needed could come just from existential instantiation, then it seems
        that you could just use pure logic. But existential instantiation does
        not get you lower-order correlates of the propositional function.
        Assuming the axiom of reducibility, they really gave up the idea of
        reducing mathematics to logic (and admitted as much).
    \item
       It's pretty similar with the axiom of choice, that if you have a set of
       non-empty overlapping set there's another set that picks one element
       from each of them. To Vann, it seems very obvious if you're thinking
       about classes as collections (you can always form the product space and
       find a projection). If you're thinking not in terms of classes but in
       terms of propositional functions and classes as things that we construct
       by constructing predicates, then there's not really intuitive grounds
       for axiom of choice. If you have infinitely pairs of socks, then there's
       no reason you should be able to form a predicate of only one from each
       pair (??). If you think of sets as being created by some form of mental
       process, then the axiom of choice seems dubious.
    \item
        The Banach-Tarski paradox says that you can cut up a sphere of diameter
        1 into pieces and re-assemble the pieces into two spheres of length 1.
        You need the axiom of choice in order to create the cut. Some people
        thin kit's a problem and other's don't. Why it seems like a problem is
        that you get 8x as much matter for free (it seems). Others say that it
        just seems like a problem because we expect volumes to be preserved,
        but if you think of how volume is defined (you get volume of a sphere
        by inscribing polyhedra inside and outside the square and taking the
        limit of many faces), but you can never really close the gap between
        the inside/outside and the sphere. 
    \item
        Russell had two motives for adopting the vicious circle principle: he
        wanted to respond to the set-theoretic paradoxes and he wanted to
        respond to the semantic paradoxes. In the introduction to
        \textit{Principia Mathematica} there is some talk about the semantic
        paradoxes. Ramsey proposed that we distinguish between the semantic
        (epistemic) paradoxes from the set-theoretic paradoxes. For the
        purposes of creating a foundation of mathematics you just focus on the
        set-theoretic paradoxes. Then you realize that you don't need the
        vicious circle principle to solve the set-theoretic paradoxes when you
        have the axiom of reducibility. Ramsey suggested that you scrap order
        altogether and just arrange the propositional functions so that a
        function just has to be a higher type than its arguments. Quine took
        that a step further: Frege wanted to talk about classes, Russell wanted
        to replace that with talk of propositional functions. Quine noticed
        that the talk of propositional functions was intended for the logical
        reduction project, but since that failed we might as well go back to
        talking about classes. So we had individuals, classes of individuals,
        relations (binary/ternary/so on) between individuals, binary relations
        relating classes to classes, individuals to classes, etc. So you end up
        with this structure that is still kid of complicated but still much
        simpler than Russell's solution.
    \item
        Norbert Weiner saw that even that picture could be simplified by
        instead of talking about relations, let's identify a relation with a
        class of ordered pairs/triples/etc. (identify $<a, b, c>$ with $<a, <b,
        c>>$. So you can just talk about individuals, classes of individuals,
        classes of classes of individuals, etc. Weiner's idea was that you
        didn't have to treat ordered pairs as primitive. The law of ordered
        pairs says that $<a, b> = <c, d>$ iff $a = c$ and $b = d$. Norbert
        noticed that you could take $\{\{\{a\}, \emptyset\} , \{\{b\}\}\}$, and
        you can verify that this satisfies the law of ordered pairs. There are
        more brackets than you'd think because he was working in the theory of
        types and need to be working with things of the same type. With this
        simplification, what started as a monstrously complicated system becomes
        very simple.
    \item
        To get mathematics, he needed infinitely many individuals. If you have
        only finitely many individuals, no matter how high up the hierarchy he
        went you'd still only have finitely many things. But if the individuals
        about which you're talking are physical objects than it is actually
        pretty dubious that are infinitely many. So they added the Axiom of
        Infinity and they didn't regard it as obviously true.
    \item
        There's still one feature of that project that is still kind of
        anomalous. You want to say that there are 8 people in the room, and how
        we're going to make sense of that is by saying that the number 8 is the
        collection of all 8-element classes of individuals. So a number is a
        class of classes of individuals such that every class of individuals
        that can be put in one-to-one correspondence with a member of the class
        is a member of the class. What is still peculiar about this theory of
        types is that you can't mix types which means you can't use the same
        numbers to count individuals as to count classes of individuals. So
        there's a different number system of each type and there are infinitely
        many systems of natural numbers. It's not fatal, but it's just a little
        fussy and seems kind of artificial. 
    \item
        G\"odel stepped in a suggested that there is no good reason not to make
        the classes cumulative instead of only allowing members of type $n - 1$
        in classes of type $n$. Originally, we wanted this hierarchy of classes
        in order to protect us from the paradoxes and the vicious circle
        principle, but we've given up the vicious circle principle. He noticed
        that we get the paradoxes when we ask whether a member of the class is
        at the same type as the class, and so we can lighten the restriction to
        allowing any type below the class, not just the one type just below it.
        Originally, we get the type hierarchy from a grammatical restriction on
        concepts/objects, but once you allow cumulative classes you need to
        abandon the grammatical distinction - so you say that you won't make
        type distinctions among the things we're talking about as far as logic
        is concerned.  Some of the things we will talk about are individuals,
        sets of individuals, and so forth, but we're going to be able to talk
        about those all at once without distinguishing between them (there's
        only one kind of variable for the logic). What gets us the hierarchical
        structure is not a grammatical restriction but rather an axiom that
        tells us that the sets are well-founded. so in G\"odel's system you
        have a very simple logic (first-order predicate calculus) but you have
        a lot of not simple axioms guaranteeing the existence of sets. 
    \item
        So it looks as if there is no hope for reducing mathematics to logic,
        it looks like Cantor and Dedekind won. The advantages of a logical
        conception of set over a combinatorial conception of set disappear once
        this project doesn't work. And ZF set theory is so much more powerful
        because it can extend into the transfinite. But this is also possibly
        bad because it can make it more vulnerable to contradiction. Still
        there are lot more points that have gone to the combinatorial
        conception rather than the logical conception. There is still a lot to
        be desired and it's a big loss to have mathematics be synthetic a
        priori rather than analytic. 
    \item
        G\"odel's incompleteness theorem throws a wrench in the works by
        showing that there are arithmetic truths that we can recognize as true
        that aren't derivable from the axioms, and that even if you add more
        axioms there are still more truths that aren't provable.
    \item
        More recently, the Neologicist program has been trying not to get us
        all of ZFC but rather to get us mathematics strong enough in order to
        serve or purposes will staying in an (arguably) logical framework.
    \item
        Dedekind proved that arithmetic is categorical, but if you think of
        arithmetic as a first-order theory the way we do know, then that is not
        categorical (it is not a second-order theory). You get induction from a
        quantification over properties and you get categoricity from induction.
        But when you do things in a first-order framework you have an axiom
        schema for induction and so you have infinitely many induction axioms
        instead of a single second-order axiom. But then this new set of axioms
        isn't categorical and by G\"odel's work isn't complete. 
    \item
        The next part of our story is going to be a revival of second-order
        logic as something we can do in the context of modern mathematics when
        we're well beyond the \textit{Principia} stage. That revival is due to
        George Boolos. Next time, we'll talk about Boolos and Quine and then
        we'll start talking about Benacerraf. Read Quine and Boolos articles.

\end{enumerate}

\section{March 15, 2017: Quine's Nominalism}

\begin{enumerate}
    \itemsep0em 
    \item 
        Quine really wants to be a thorough-going nominalist. He wants to deny
        that there are any abstract objects. But he doesn't think he can do it
        for reasons that we'll spend most of April talking about. Right now,
        we're going to talk about his more-limited version of nominalism. 
    \item
        He's willing, albeit reluctantly, to concede that there are such things
        as classes, but he wants to deny the existence of universals and
        properties. His reasons for doing that are mostly having to do with the
        obscurity of the identity conditions for properties.
    \item
        You can tell whether two classes are the same, which is in the case
        where they have all the same elements. It is hard to tell whether two
        properties are the same. It's interesting that Russell went the other
        way, trying to get rid of classes and use only properties.
    \item
        It doesn't really matter to us that Quine wants to deny that they are
        properties. What is a more interesting question is how is that even an
        intelligible thought. We see all the dogs and are able to distinguish
        all the things that are dogs from those that are not dogs. How can we
        classify that which is a dog and that which is not? 
    \item
        The obvious answer is that there are some properties that dogs have in
        common and we can use those properties for our classification. Quine
        wants to deny that there are these properties that the dogs have in
        common. 
    \item
        One approach is to take the nominalist view that the only thing dogs
        have in common is the name we give them. But this approach is bad
        because it isn't arbitrary how we classify the dogs but it is arbitrary
        how we name them. This is how Russell thought of it. To say, 'X is a
        dog', 'Y is a dog', and 'Z is not a dog' all logically entail that
        there is a property that X and Y share but Z lacks.
    \item
        There's this position that Quine wants to advocate that there are not
        any properties, but it is hard to formulate that in a way that a
        competent English speaker wouldn't regard as obviously false.
    \item
        The idea is that there is something that X and Y have that Z lacks. The
        thought is that there is this property that is shared between the
        former but not by the later. Question: why can't you not specify what
        they have in common but instead just say that they are both dogs.
    \item
        Or is there a difference between properties and propositional
        functions. Common doctrine is that 'that' clauses denote propositional
        functions. If you use 'that' clauses as direct objects of verbs (??)
        commit us to propositional functions.
    \item
        But Quine wants to deny that there are any propositional functions.
        Didn't we learn anything from going through this pointless complexity
        of going through the ramified theory of types. We really just need an
        inclusive view of what objects there are. In particular, we don't need
        a special logical category for propositional functions. Just put them
        in the same domain as your quantifiers. It's going to make our life
        more complicated without adding much by build distinctions (like type
        distinctions) into the logic. So for type distinctions we just need
        some way to demarcate the differences within the universe of the domain
        of the quantification instead of adding logical distinctions. 
    \item
        Quine's answer to his own question: first, he has a nice slogan. "To be
        is to be the value of an variable", which tells us a method for
        answering the question of what the ontological commitments are of a
        given theory. That seems to be as far as it goes but really doesn't
        seem to go very far at all because anybody who doesn't agree that
        because X, Y, and Z all walk on four legs and share the property of
        being four-legged. Anyone who wants to deny that is not a competent
        speaker of English. 
    \item
        Quine proposes that this criterion is right but in order to employ it
        you need to enter a process of translating English into a canonical
        form where you are trying to fully make the commitments of your theory
        as explicit as possible. In particular, Quine says that if you want to
        make it explicit what the ontological commitments of your theory are,
        then reformulate the theory within the first-order predicate calculus.
        Then, the things that have to serve in the variable place tell you what
        the ontological commitments of your theory are. He doesn't think this
        is obligatory but he thinks that if people refuse then it means that
        they are refusing to make their own logical/ontological commitments
        explicit.
    \item
        It seems like this is demanding too much. The machinations Carnap had
        to go through in order to talk about disposition terms (??) in the
        first-order predicate calculus. To talk about what it means for a
        chemical to be soluble: you know that water dissolves sugar, soy ou can
        see which particular samples of sugar dissolve and you can predict
        which won't. You can predict that sawdust cannot dissolve. So a natural
        formulation is $x$ is soluble iff $x$ dissolves when put into water.
        But if you use this as your material conditional, you'll get that
        things that are never put into water are soluble. But you don't want
        that. Carnap went through this big effort to try and figure out a way
        to express solubility in the first-order predicate calculus by saying:
        if a theory of solubility contains two axioms:
        \begin{enumerate}
            \item Dissolves in water
            \item Two identical substances either both dissolves or neither of
                them does. (??)
        \end{enumerate}
        But if something is never put into water and nothing else like it is
        ever put into water than you cannot say that is it not soluble.
    \item
        You get something that looks a lot more natural if you're allowed to
        understand the conditional that $x$ is soluble if it dissolves when put
        into water - to understand this is a much more strong material
        conditional (if it were put into water, it would dissolve) - that seems
        like a use of disposition terms is deeply entrenched in our efforts to
        describe the world in science and without. And our use of
        counterfactual conditionals is also a very fruitful usage. It seems
        necessary restrictive to go with Quine and restrict to the
        lower-predicate calculus.
    \item
        But if you accept Quine's criteria you seem to be getting bogus
        ontological commitments inasmuch as you want to understand disposition
        terms in terms of counterfactuals. Well, you can't take counterfactual
        usage as primitive because you have to ultimately formulate things in
        terms of the predicate calculus, but you cant take such usage as
        defined by adopting a possible world semantics. $x$ is soluble if it
        would dissolve in the closest possible world. But we wanted to avoid
        talking about possible worlds because we wanted only to look at what is
        around us and speak about that.
    \item
        Vann wanted to return to the discussion we were having last time about
        the possible skeptical conclusions from the L\"owenheim-Skolem theorem.
        Beyond our theorizing, there is a use of number talk in counting and
        measuring that doesn't really seem to get us significance beyond what
        we get from just the theorems. The fear is that if we accept Quine's
        mandate to restrict ourselves to first-order logic, we seem to be
        forced into some sort of skeptical position. Our mathematical theories
        don't have a unique intended model. That is something that we saw
        already from Dedekind and that's something we feel like we can cope
        with. What Dedekind did was to capture the real and rational numbers in
        a way that was unique up to isomorphism, but didn't go any farther than
        that to specify which of the isomorphic structures was the real number
        system. Look at how Dedekind develops the theory: that his terms
        doesn't have uniquely determined referents doesn't seem to cause any
        problems for the way he does mathematics, even just for practice;
        classifying up to isomorphism it seems good enough. Take whatever our
        mathematical theory is, assuming infinite models, it is going to have
        wildly dissimilar infinite models that don't resemble each other at all
        structurally.
    \item
        Something Putnam wants to insist on is that we don't appeal to occult
        powers of the mind to see how our terms latch on to their determinate
        referents. But we're not we're just using number talk that leave it
        drastically undetermined what the referents of our terms is. We get a
        kind of skepticism that is upstream from the kind of skepticism you get
        from thinking about whether theorems/axioms are really true.  This is
        at a level of skepticism that beings even earlier. Nevermind how you
        know they're true, how are you going to have mathematical beliefs if
        supposedly beliefs are about these objects but there is nothing that
        you do that is even close to picking out those mathematical objects.
    \item
        Skolem's paradox was from the early paradox and was easily answered
        just by saying that you get the elementary submodel by neglecting some
        functions that we know are really there. So, yeah, if you neglect
        things you can get a theory that looks just like our theory. That looks
        like a sleepy little paradox. But then Putnam took it and made it look
        like a very serious paradox, both inside and outside of mathematics.
    \item
        There's a way to get around the paradox which is to do what Dedekind
        did and say that contemporary mathematics' describe the natural numbers
        etc. as models of a first-order theory. Dedekind proceeded differently:
        wrote down his axioms as a second-order theory where he could range
        quantifiers over properties and was able to prove categoricity (that
        his axioms actually determined the real or natural numbers uniquely up
        to isomorphism). But his proof took place within this second-order
        theory, Can't we reapply the L\"owenheim-Skolem argument to the higher
        theory. Unless we assume that we have some grasp of what properties
        there are that can't be explained in how we use property talk. So you
        just get back to using occult powers of the mind again. 
    \item
        There's an answer to Skolem's problem that claims to be different than
        just kicking the problem upstairs to higher-order logic. Though whether
        or not it really is different is controversial. The alternative answer
        started with Peter Geach with the project of formulating ordinary
        English sentences into ordinary language. He was particularly
        interested in the use of plural noun phrases. Take the sentence: "there
        are some critics that only admire one another". The sentence "there are
        some critics who just admire impressionists" can be formulated easily
        in a first-order idiom. But "there are some critics that only admire
        one another" can only be expressed in a first-order idiom if we can
        appeal to the use of classes. 
        $$(\exists S)((\exists x) x \in S \centerdot (\forall y)(y \in S
        \Rightarrow \mathrm{Critic}(y)) \forall x \forall y(x \in S \centerdot
        \mathrm{Admire}(x, y) \Rightarrow y \in S))$$
        But then:
        $$(\exists S)(\exists x Sx \centerdot \forall y Sy \Rightarrow
        \mathrm{Critic}(y) \forall x \forall y S x \centerdot
        \mathrm{Admires}(x, y))$$
        But if I say that there are critics who admire each other it doesn't
        seem like I am telling you anything about classes and you could imagine
        someone who is a strict nominalist and certainly believe that there are
        critics, you can think anything you like about their group relations,
        and you can belief that there are critics who admire only one another,
        but you can't be a nominalist and only belief this sentence. If you
        accept the commonly held believes about sentences then you learn that
        there are the same truth conditions for the first and second sentences
        but you may belief the things about critics without believing the
        reformulation.
    \item
        You can't formulate the statement about classes just in terms of
        first-order logic; take the sentence: "there are some critics who only
        admire one another". That sentence has the same form as "there are some
        non-zero natural numbers that are adjacent only to one another" but the
        latter sentence is only going to be true in a non-standard model of
        arithmetic. If you could successfully formulate in first-order logic
        that there are some critics who only admire one another then you could
        successfully formulate that there are some non-zero natural numbers
        that are adjacent to one another, then you could construct a sentence
        that is true in the standard models but not in the non-standard models.
        But then it is not possible to give a categorical description of the
        natural numbers system.
    \item
        Boolos proposed that the correct way to understand that kind of use of
        plurals we see in the last sentence is by taking a different kind of
        the use of the quantifiers. We have quantifiers that range over
        individuals, second-order quantification where they range over
        properties. Boolos is proposing the notion of plural quantification
        where the variables range over individuals and the difference is that
        in singular quantification the variables range over individuals one at
        a time while with plural quantification the quantifiers range over
        individuals many at a time. So there is in the semantics for
        first-order predicate calculus a variable assignment is a function
        assigning a value with each of the variables. Then you inductively
        define what it is for a variable assignment to satisfy an open
        sentence. 
    \item
        There are critics who only admire one another with: $$\exists xx
        ((\forall y)y \in xx \rightarrow (\mathrm{Critic}(y) \centerdot
        (\forall y \forall z) (y \in xx \centerdot \mathrm{Admire}(y, z))
        \Rightarrow z \in xx))$$ Note the $\exists xx$ which is the plural
        quantifier. This theory doesn't postulate any new things and doesn't
        add any new attributes or properties to get the range. Both quantifiers
        range over individuals. The plural variables are as restrictive because
        you can have multiple individuals instead of just one: you have to
        associate at least one individual but you can associate more than one.
        Once we have plural quantification we get our categorical descriptions
        of the objects of classical mathematics. 
    \item
        The key to describing the natural numbers if: for any set of natural
        numbers, there is one among them that is less than all the others. If
        you want to classify the real numbers, you have to know: for any real
        numbers, if there is a number that is greater or equal to all of them
        then there is a least number that is greater or equal to all of them.
        Zermelo formulated the separation principle in terms of definite
        properties, people weren't happy with brining the metaphysics of
        properties into set theory so Z said that we should formulate it instead
        as a first-order theory, with the difficulty that the first-order
        schemata admits non-standard models. Now that we have plural
        quantification, we can say that for any set $X$, $\forall x \in X$,
        $\exists Y$ such that only the $x$ such taht $x \in X$ are members of
        $Y$. W ecan similarly give a plural quantification version with the
        replacement axiom schema. Vann will embarrass himself if he tries and
        says it, but there is a second-order formulation of the replacement
        axiom, if you insert the replacements into ZF set theory then you do
        not get a categorical representation but you get instead ZF axioms and
        their plurally quantified versions and the fact that for any two models
        of the axioms either they are isomorphic or one of them is isomorphic
        to an initial segment of the other, which you get by clipping off the
        taller model. So that means we don't get a categorical generalization
        of the universe of set theorem.
    \item
        The continuum problem comes from Cantor's proof that the number of real
        numbers is greater than the number of natural numbers. Are there any
        infinite sets with cardinality between the two? That question is going
        to have a definite answer, especially if we're using plural
        quantification. The axioms of set theory do not have a uniquely
        determined model, but they are just alike to the part of the model that
        is smaller, and the real numbers and all the functions defined on them
        are in the part of the universe below the first inaccessible, and so if
        the continuum hypothesis is true an one model of ZFC reformulated in
        terms of plural quantification, then it is true in all the models and
        so the continuum hypothesis is going to have a definite answer. It
        would take a bit of patience to verify or disprove the continuum
        hypothesis because you have to check equinumerosity with all possible
        subsets of the real numbers, of which there are one or two.
    \item
        We have lots of results about things being undecidable in first-order
        ZFC. The only things we have that are undecidable in second-order ZFC
        will be if it implies some large-cardinal axiom. If you can prove that
        this sentence proves the large-cardinal axiom and you think it's
        consistent (but you can't prove it), then that will tell you that it is
        independent of plural quantification of ZFC. There also aren't that
        many second-order models just like with first-order models. It's so
        hard to construct models that there is hardly anything to say about
        second-order model theory.
\end{enumerate}

\section{March 20, 2017: Benacerraf, "What Numbers Could Not Be"}

\begin{enumerate}
    \itemsep0em 
    \item 
        Von Neumann and Zermelo had different set-theoretic definitions for the
        natural numbers: $3 = \{2\}$ for one and $3 = \{0,1,2\}$. It seems like
        they are two ways of representing the same thing; but it also seems
        like these are two ways of misrepresenting because you don't really
        have strict identity here.
    \item
        They're following a tradition that begins with Dedekind: you get an
        infinite set if you can it can be put in one-to-one correspondence with
        a proper subset of itself, and then you get a simply infinite set by
        taking something that is not in the image of the one-to-one function
        and then repeatedly applying the one-to-one function to it. Dedekind
        identified a simply infinite set and then said that we can take the
        natural numbers to be any simply infinite set we'd like. But if you
        really do it that way that it seems like each of us can have our own
        choice for what is the natural numbers; how would we be able to
        communicate? 
    \item
        Paul Benacerraf, who gave us this parable, said that each answer works
        equally well and so there is no reason to prefer one over the other. In
        fact, any simply infinite progression will be a satisfactory
        representation of the natural number system (originally with
        recursiveness, later he realized he doesn't need it). 
    \item
        Some definitions may serve better use or be more aesthetically
        pleasing, but this is a question of the referent of a term and about
        the definitions of the natural numbers.
    \item
        Benacerraf specified that the progression needed to be recursive, but
        here it is a bit unclear what is meant by a set of sets being recursive
        (rather than a set of integers). Something maybe like the method of
        counting to obtain numerals needs to be recursive. It is easy to
        understand the association of numerals with sets of sets and to ask
        which of those types of sets constructions are recursive (there is ID
        between an algorithm and a recursive set of integers). Recall that
        $V^\omega$ is the set of finite sets all of whose members are finite
        sets all of whose members are finite sets, and so on. From that
        perspective, it seems that Benacerraf is requires a much stronger
        condition: that the progression has to consist of elements from
        $V^\omega$. 
    \item
        Once you identify the natural numbers with some simply infinite
        progression, then you can define the operations of addition,
        multiplication, and less than on that infinite progress and then after
        that you just treat members of that infinite progression in exactly the
        same way as everyone learns to treat numbers. The fact that we are
        talking about sets here doesn't make any different for how we do
        arithmetic or counting. What is important is that the series is simply
        infinite, but once you have that then arithmetic doesn't change.
    \item
        We want to reduce number theory to set theory, so we're going to say
        that every numeral denotes a set. The embarrassment is that you need
        the numerals to name sets in some such way that you never have two numerals
        denote the same set, but beyond that it looks completely arbitrary
        which sets you choose. Why that is troublesome is that, if the numerals
        are names of numbers, then for a name to be part of a non-fiction story
        it must have a referent out in the world. So we have these numerals
        that grammatically act like names but have no referents, then are we
        saying that arithmetic is just a fiction. Benacerraf sees this as
        pushing us towards a skeptical conclusion. the idea is that, for a long
        time, people thought that the Iliad and the Odyssey were entirely
        fictitious and that there was no place as Troy. So if the Iliad is an
        entirely fictitious story, then there wouldn't have been any such city
        as Troy. There is (was) such a city, so the Iliad is not entirely
        fictitious. If there is nothing out there in the world that is referred
        to by "3", then is it fictitious? This situation is similar to color
        words ("red") in that you can use "red" both as an adjective and as a
        noun. When you use "2" as an adjective, you are going to us a plural
        noun; with color, you can also use with a singular noun (but you can't
        with "2").
    \item
        Benacerraf ends the article with a bewildering sentence: "there are no
        such things as numbers; which is not to say that there are not at least
        two prime numbers between 15 and 20". What the heck does that mean?
    \item
        Here's a possibility: does this all come about because people decided
        they wanted to reduce arithmetic to set theory? Zermelo was keen on
        having set theory as the foundation of mathematics (it makes for an
        efficient theory with a clean ontology). Do the problems we've been
        talking about persist even without the set theory?
    \item
        Vann asks: could we have an example of an intrinsic problem? Maybe
        self-identity or being abstract? It really seems right to say that
        Gauss knew what the numbers were, although he certainly did not have
        any reduction of number theory to set theory. Maybe the problem is
        thinking that number theory should be reduced to set theory, maybe the
        problem is to say that number theory can be ontologically reduced to
        set theory (as in, you can identity numbers with sets). Maybe the
        reduction of number theory to set theory went one step too far: the
        really useful thing was to see that the natural numbers are isomorphic
        to the several simply infinite progressions identified by Von Neumann
        and by Zermelo. That turns out to be really useful because set theory
        has powerful mathematical methods that aren't going to be available to
        you if you restrict your attention to numbers (there are features of
        $\mathbb{N}$ that are only recognizable by the methods of higher
        mathematics). But as an ontological reduction if you say that the only
        things there are are sets, then your mathematics doesn't change - you
        get all the mathematics from just realizing that $\mathbb{N}$ is
        isomorphic to the simple progressions. The new theorems you could
        prove after making the identification are things like $7 \in 17$. Vann
        is wondering if this is all a tempest in a teapot, where you get these
        difficulties and this controversy because you are insisting that the
        numbers are actually identical with the sets - but there is no benefit
        in that. Just say that numbers are their own kind of thing or throw up
        your hands and not decide whether the numbers are sets or not.
    \item
        There were some really good motives that lay underneath the reduction
        of mathematics to set theory: one is that you need uniform definitions
        that could be understood across the different branches of mathematics
        (there is a lot of crossover in the field). You can't cross over if the
        definition of continuity in complex analysis is at odds with the
        definition of continuity in another field. In the 19th century, there
        were lots of quarrels because there weren't good definitions. There is
        agreement among mathematicians about what constitutes a valid proof,
        but this doesn't require the identification of the natural numbers with
        steps. It maybe leaves you with a slightly bloated ontology because now
        you have both sets and numbers instead of just sets, but the benefits
        of ontological reduction aren't all that great when the reduction isn't
        all that efficient. For example, reducing heat to molecular kinetic
        energy actually explains what heat is, but reducing natural numbers to
        sets doesn't add any explanatory power. 

\end{enumerate}

\section{March 22, 2017: Benacerraf and Structuralism}

\begin{enumerate}
    \itemsep0em 
    \item 
        Last time we talked about Benacerraf and his alarming conclusion that
        it is not possible to have knowledge about mathematical objects. Two
        parts to this: first, assuming that there are mathematical objects, we
        can't have any beliefs about them because to have beliefs about a thing
        you have to be able to refer to a thing, and to refer to a thing you
        have to be able to pick it out. We aren't able to pick out a unique
        referent for any of our mathematical terms because the referents of
        those terms are at best determined up to isomorphism, and so if there
        are mathematical objects we aren't able to have beliefs about them.
        Second, assuming for the sake of argument that we are able to have
        about them, there isn't the right connection between our mental states
        and those things in order for those beliefs to count as knowledge.
        That's the conclusion he comes to and doesn't think he can escape from
        it (see the last sentence of the paper). 
    \item
        There is an analogy to Little Red Riding Hood: she doesn't exist, but
        within the story there is still a wolf between when she leaves and when
        she reaches her destination. similarly, there are no numbers but within
        the story of numbers there are at least two primes between 15 and 20.
    \item
        The first part of the argument is that if there are mathematical
        objects then we can't have beliefs about them. Tarski's theorem
        requires knowing what the names refer to, but Benacerraf shows that
        they can't have any reference at all. For number claims to be true,
        the names have to refer. So truth-conditional semantics for mathematics
        can never get off the ground. If we want to say that mathematical
        statements are true, then that commits us to give them
        truth-conditional semantics. If the truth-conditional semantics for
        mathematical language has lower requirements than the rest of the
        language, then at best mathematics gets a lower status than the rest. 
    \item
        The question that came up at the end of last time was how we can choose
        a preferable candidate amongst a set of candidates for the referents
        of the natural numbers. But even if there was just one candidate we
        showed that a permutation among the elements of that candidate would
        still be a valid candidate, and so you're stuck with the same problem.
    \item
        Benacerraf lays down a pretty demanding condition: that the
        compositional semantics needs to be uniform for different parts of the
        language. So if you have a semantics that tells you that for empirical
        statements that don't involve number you have a referential semantics
        based on your ability to refer to empirically found things, and then
        for mathematical semantics you don't use a referential semantics. But
        we want a homogeneous semantic theory. So Benacerraf would be
        dissatisfied by the idea that God can just fix the reference of the
        numerals.
    \item
        There's the broadly structuralist idea that mathematical objects are
        only determined up to isomorphism. What we have are a bunch of intended
        models of mathematical language which are all isomorphic to one
        another, and even though none of those is preferred the same sentences
        are going to wind up being true in every model. For mixed statements,
        you're going to have a bunch of models that agree in what values they
        assign to the empirical terms, but different models are going to
        disagree in what they assign to the mathematical terms, but you know
        that the referents of the mathematical terms are isomorphic and so you
        know that the truth-conditions for the mathematical and empirical
        statements (and the joint statements in counting and measuring) are
        going to be the same in all the models. It's just going to be questions
        like whether $3 \in 17$ that is going to have different answers in
        different models. Benacerraf is going to reject this because it ends up
        not yielding a homogeneous semantics. Any two intended models are alike
        in what they assign to the empirical terms yet differ in what they
        assign to the arithmetical terms, but the referents they assign to the
        arithmetical terms in the models are going to be isomorphic to each
        other. So you get really different truth-conditions for atomic
        sentences, but once you get the truth-conditions for the atomic
        sentences the compositional semantics will be the same.
    \item
        There's an attitude prevalent in Quine that if you're going to have any
        abstract objects, then the mathematical ones are the least problematic
        ones to admit into your ontology.  The reason for thinking that is that
        for the mathematical objects you have definite identity conditions, but
        for properties and propositions you do not have definite identity
        conditions. For Quine, the lack of definite identity conditions was a
        fatal defect ("no entity without identity").
    \item
        The only real obligation of a semantic theory is to get the
        truth-conditions of sentences right. And the Benacerraf arguments (the
        permutation argument) doesn't really cause any problem with this
        because it doesn't attack whole sentences, just the referents of
        individual terms.
    \item
        Is this the right thing to say? We have indeterminacy of mathematical
        referents, but there is nothing special about mathematical referents
        here - we have indeterminacy of reference everywhere we look (e.g.
        abstract objects). This almost seems more troublesome.
    \item
        Maybe you could bring in a causal constraint in the non-mathematical
        case rather than the mathematical case. This is definitely what
        Benacerraf had in mind - that the crucial difference was that you could
        have a compositional semantics where you have a referential semantics
        for atomic terms (??) which is just a causal theory of reference. So
        we're back to Putnam's reply that a causal theory of reference is just
        more theory. For Sk\"olem, he takes it for granted that we have a
        meta-theory and in the meta-theory we can describe these different
        models and see that countable model of set theory is unintended even
        all the right sentences come out true. Putnam said that if we have a
        meta-theory that we can regard as fixed and stable, then in the
        meta-theory if you assume that your terms refer than it isn't very hard
        to get determinate referents in the object theory.
    \item
        A reason why the permutation argument is better than the original
        Lowenheim-Sk\"olem argument is that the latter is very specific about
        first-order languages. But we don't do scientific or mathematical
        inquiries in a first-order language. But the permutation argument is
        much more versatile and applies to higher-order logic (in which the LS
        argument completely collapses) or even in model languages (permute the
        possible individuals in the possible-world semantics; you get all the
        right truth values for the modal and counterfactual sentences as well
        as for the vanilla sentences). That particularly matters because what we
        require of an adequate semantics isn't just that it gets us the right
        truth values, it's that it gets us the right truth-conditions.

\end{enumerate}

\section{April 5, 2017: The Inscrutability of Reference}

\begin{enumerate}
    \itemsep0em 
    \item
        Last time we were caught up in the inscrutability of reference.
        Consider the sentence "Mr. MacGregor chased Peter Rabbit." There is one
        theory of reference that tells us in that sentence that the name "Mr.
        MacGregor" refers to Mr. MacGregor and the name 'Peter Rabbit' refers
        to Peter Rabbit and 'chased' refers to the action of chasing. Another
        theory of reference is: the name 'Mr. MacGregor' refers to Mr.
        MacGregor's unit set, 'Peter Rabbit' refers to Peter Rabbit's unit set,
        and the word 'chases' refers to the relation one unit set bears to
        another if the unique element of the first thing chases the unique
        element of the second thing. So we have two theories of reference and
        it looks like the two theories of reference do an equally good job of
        accounting for truth conditions, assertion conditions, etc. of the
        language.
    \item
        How do you refer to actual things in the second theory if you can only
        refer to unit set? Vann had the idea that you could have the
        permutation of MacGregor and the unit set with MacGregor. This is
        really weird if you try to describe the other theory of reference, it
        looks like for some reason when I want to talk about Mr. MacGregor you
        wind up only talking about the unit set of Mr. MacGregor.
    \item
        The thoughts underlying the inscrutability of reference are that the
        two theories of reference do an equally good job of accounting for how
        the speakers of the language use it. There is nothing more to making a
        semantic theory correct than its ability to account for the way
        speakers use their language.
    \item
        With the second theory, how can you refer to the class of everything if
        your referent has to be greater than that? The answer is both there is
        no class of everything and that you're just permuting, not adding
        anything.
    \item
        There is nothing more to linguistic meaning that just what the users of
        a language mean when they use it, the only way to say that one theory
        of reference better is to find a place where one theory doesn't capture
        the way users use the language.
    \item
        You just need a one-to-one function $\pi$ that sends a element to its
        unit set and vice versa. 
    \item
        The one constraint for creating these theories of reference is from
        Quine and Putnam who said that you could permute the entire universe
        under referent and then keep all the truth values the same. Vann
        thinks that this isn't sufficient, e.g. your name can refer to a galaxy
        and the galaxy can refer to you. In this situation eternal sentences
        will be true. But the things that are wrong here is that all you are
        getting is truth values rather than truth conditions, and that you want
        to get the truth conditions for occasion sentences and not just eternal
        sentences. Vann doesn't know how you're epistemology is going to work
        if somebody tries to say that looking at you is a good way of
        determining facts of the distant galaxy. 
    \item
        There is this relation IC when somebody sees something, then the unit
        set of that person ICs the unit set of that thing. Both theories of
        reference give sense to saying 'rabbit!' when there is a rabbit
        present and not saying it when there is not.
    \item
        For the first theory of reference, the term 'sets' refers appropriately
        but for the second one the definition is very wacky and the term refers
        to thing that either aren't sets or aren't sets of singletons. The well
        seasoned answer is the one Goodman trotted out when people objected to
        his groom example. They say: 'the way you use "green" makes it look
        like my use of the word "green" is really weird because there was a
        time when all the green things stopped being green'. But there are
        objective facts with 'set' where one is right and one is wrong. Vann
        thinks: there is a physical antecedence to the color referents
        (physical similarities in reflection patterns) that have caused the
        usage to be universal. So in the new theory there are drastic
        differences in the reflection patterns. Can we say the same thing about
        the set case? There are ways that certain sets are grouped together
        that seem similar to the natural differences in the 'green' case. 
    \item
        This is getting to a really crucial part of the argument: spectral
        reflections really are a natural property (physics), but the natural
        distinction between sets and non-sets isn't something that physics
        tells us about. It looks like 'naturalness' was invented because if we
        don't have natural properties that serve as reference magnets, then we
        wouldn't have inscrutability of referents, but we want those and so we
        admit the natural properties. But these 'natural properties' aren't at
        all like the actual properties that we find in nature. There is a more
        basic doctrine underlying it that the constraints on the semantic
        theory is that it's got to get truth/assertion/acceptance conditions
        right at the level of whole sentences. At the level of whole sentences,
        systematic ways of manipulating what the parts refer to that cancel
        each other out don't make any difference at the level of whole
        sentences and the only thing that determines the meaning of the word is
        its contribution to the semantic values of the sentences that contain
        the word. That's a crucial doctrine that people are relying on for the
        inscrutability arguments. There is only going to be a fact of the
        matter at what happens at the sub-sentential letter; the thought is
        that the beauty of permutations is that anything you do at the
        sub-sentential letter gets cancelled out - for example what you do with
        names gets cancelled out by what you do with predicates. 
    \item
        Peter Rabbit and the set of natural numbers have something in common.
        For the first theory of reference they have nothing in common, whereas
        for the second one they both are sets. 
    \item
        If we have rival semantic theories, part of having rival semantic
        theories is having different accounts of which properties fall under
        the extension of 'natural'. Can we just kick the problem up a level and
        say that the two classifications are natural/unnatural just according
        to the semantic theory you are using but it's fine for my semantic
        theory. It looks like your theory of naturalness is indeterminate just
        like how all the other theoretical terms are indeterminate.

\end{enumerate}

\section{April 10, 2017: Structuralism}

\begin{enumerate}
    \itemsep0em 
    \item
        Hilbert talked about making a system of geometry where point, line, and
        plane are played by ball, beer mug, and car and it would be a perfectly
        fine geometry. Frege disagreed. This was a point where people stopped
        looking for a unique model, and is the break between old/new (even
        though Frege was so ahead of his time). Vann understands structuralism:
        what distinguishes the assertoric from algebraic system is that the
        assertoric systems have an isomorphism class of intended models.
        Algebraic systems also has a bunch of models but with assertoric systems
        the intended model is unique determined up to isomorphism. According to
        structuralism to ask what is the intended model for arithmetic is a
        misguided question. Van has been thinking of structuralism as a
        semantic thesis that you get by looking at the language of mathematics
        from the outside, and it's a thesis about the inscrutability of
        reference-it's saying that the referents of mathematical terms are not
        uniquely determined. Structuralism just says the referents of
        mathematical terms are determined only up to isomorphism.
    \item
        But after thinking about it, it's not that the referent is
        undetermined, but rather that mathematical terms refer to patterns or
        structures. So we have all these isomorphic systems that are copies of
        the natural number system, Vann has been taking the characteristic
        doctrine of structuralists to be that there isn't any such thing as the
        natural number system and that what exists are just various structures
        that all end up being isomorphic. The structuralist view as Vann now
        thinks it could be understands it is that there are all these systems
        and then there is the common structure that they share, or the pattern
        that they exemplify. So $\sqrt{2}$ refers to a particular position in
        the pattern.
    \item
        So the G\"odel sentence is part of the structure of the natural numbers
        even though it's not derivable, and so the structure is not just what
        is derivable. Dedekind thought that the axioms determine an isomorphism
        class of structures, which means that any sentence that is true in one
        of the models will be true in all of the models. So you've done enough
        to pin down the truth value of each arithmetic sentence. We can do that
        because we're using second-order axioms; if we're using first-order
        axioms then the incompleteness theorem tells us that the G\"odel
        sentence is true but not derivable. If we're using plural
        quantification or second-order logic (add to PA the LUB axiom), then
        you've uniquely characterized the natural number system so that for
        every sentence either it or its negation will be a consequence of the
        axioms, but if we use second-order then we don't have the G\"odel
        sentence (?).
    \item
        This whole discussion got started by permuting an arbitrary structure
        and the result is something indistinguishable from the first. But can't
        we do the same thing with structures/patterns? Just swap the first and
        second place in the pattern. The answer is something like a permutation
        of a pattern is the same - or is there something built into the pattern
        so that positions in the pattern aren't distinguished. The pattern
        should be the thing that encodes what all the different permutations
        have in common. 
    \item
        First, there is the idea of a natural number system. So there are some
        systems, some of them are structured, and so some of them may
        instantiate the natural number system. Along with that comes a bunch of
        relational notions of something occupying the 3 position. But we've
        gone higher order very quickly. Before we were thinking as numbers as
        objects of some sort (in the range of individual variables). Now we're
        thinking of numbers as relations relating members of a system. Being a
        natural number system is a pattern that is universal, and it's not an
        ordinary universal that is true of individuals, but rather is a
        higher-order universal that is true of individuals collectively ("these
        individuals have the collective property of being countable"). But we
        seem to have gotten very far up the type hierarchy. The two main
        structuralists are Shapiro and Resnick and they come on different sides
        of this. Shapiro is a leading proponent of the user of second-order
        methods, he thinks that a lot of mathematics has been distorted by
        people insisting on first-order axiomizations. If we want the
        foundations of mathematics to be in line with how people actually do
        mathematics we ought to do as Dedekind did and think of natural numbers
        in second-order. Resnick is a Quine student and is very skeptical of
        second-order stuff.
    \item
        A reason for not being an unapologetic mathematical realist is a
        reluctance to accept abstract things. Abstract things don't affect our
        sense organs, etc. But structuralism doesn't look to be any better
        because the patterns are abstract entities. For Aristotle, you have
        concrete things and universals aren't anything over or above concrete
        things, just looking at concrete things from an abstract POV. The
        Aristotelian view of universals takes them to be abstract in the sense
        that you're thinking about only certain properties that are relevant,
        but they still are concrete things. Platonic universals are completely
        isolated from experience. Resnick says that we're epistemically better
        of talking about patterns than Platonic numbers because patterns are
        things that we can see instantiated. 
    \item
        Anti-rem structuralism takes that these patterns exist on their own
        (they exist independently and autonomously of their instances). And the
        (en?) anti-re structuralism is the analogue to Aristotelian view; the
        pattern exist because of it's instantiation. There is an epistemic
        difficulty; the latter can say that knowledge of the patterns comes
        from knowledge of the particular instances. But there doesn't seem to
        be as many instances as patterns; there are particular difficulties
        with infinite patterns.
    \item
        How to create structure without instances? If just concrete objects,
        then just choose more than 2-to-the-2-to-the-aleph-not  because that's
        the number of spacetime regions. If you allow abstract things, just
        make one up. Or just say that the natural number pattern exhibits the
        natural number pattern and so the pattern is an instance of itself.
\end{enumerate}

\section{April 12, 2017: Science and the Existence of Numbers}

\begin{enumerate}
    \itemsep0em 
    \item
        The law of gravitation tells us that there is a number $G$ such that
        for any two spacially separated bodies with masses $m_1$ and $m_2$
        there is a gravitation whose value is $G\frac{m_1m_2}{r^2}$. All the
        principles of cosmology are derived from the fact that there is one
        such number. One might say that the Sun is pulling the Earth towards
        it, and you'd naturally conclude that we're going to die, but rather
        the Earth travels in an orbit about the sun. But to learn about orbits
        you rely on the fact that $G$ is a constant. So the theory of $G$
        entails that the re are numbers. For philosophers, that is enough, as
        the worry of philosophers is that there might not be any numbers, and
        so if there are any numbers then we can be satisfied. 
    \item
        But $G$ has units? Isn't it just a relation between two physical
        quantities? One way to say it is that there is a number $G$ that is
        the ratio between two terms ($m_1m_2$ and $r^2$) and then the physical
        units just allow it to serve in the ratio.
	\item
        Can't we also say that it is a physical law that there are 7 people in
        this seminar room at this particular time? This is at least as true as
        the gravitation thing, so you could just say that the number 7 exists
        by the same form of argument. Is that any different?
    \item
        Rephrase $\exists_{\ge 1} xFx$ as $\exists x F$ and rephrase
        $\exists_{\ge 2} x Fx$ as $(\exists x)(Fx \centerdot \exists_{\ge 1} y
        Fy \centerdot y \ne x)$, rephrase $\exists_{\ge n + 1} xFx$ as
        $(\exists x)(Fx \centerdot \exists_{\ge n} y (Fy \centerdot y \ne x)$.
        There are exactly $n F$s if there are at least $n$ and at most $n$ Fs.
    \item
        So there is a law of nature that entails that there is a real number.
        So if you are going to deny that there are real numbers then you are
        going to have to deny the law of nature. Wherever you look throughout
        the sciences, you find mathematical methods being used. The striking
        difference between modern science and the science of the ancients is
        that the ancients used numbers to measure lengths and areas and other
        things whose properties could be understood in terms of measurements.
        Most of ancient science made use of qualitative descriptions without
        mathematics. pretty much any scientific claim that you want to commit
        yourself to is going to have a similar status to the law of gravitation
        in that th is going to entail the existence of numbers. The argument is
        that pretty much anywhere you look in science you are going to find
        judgments that entail the existence of numbers and so if you deny
        numbers you are going to have to repudiate those numbers. 
    \item
        Why is this a semantic thing instead of just a syntactic thing? The
        existence of $G$ could just be within the formal language used to
        expressed the law of gravitation. But that $g$ is the same for any two
        physical bodies means that there actually must be an underlying number.
    \item
        We use mathematical objects to describe things, but mathematical
        objects are not useful for explaining things. The thought is: I want to
        buy a TV cart. I want to be able to describe in some detail the cart
        that I want. To describe the cart in detail without a lot of extra
        effort I am going to use a tape measure and measure the dimensions of
        the cart and then buy a cart that fits my dimensions. You could also do
        this relationally by saying that the cart is bigger than the chair but
        smaller than the couch etc. 
    \item
        One difference between numbers and physical objects are that numbers
        are useful for describing what we see, but numbers aren't useful for
        explaining why something is. But stuff like what molecules of water
        bounce around each other in certain ways ; before people understood
        Brownian motion people thought that molecules were really part of
        reality or they thought the they were like infinitesimals in calculus,
        but that's not reality which is that it is infinitely indivisible. As
        late as the end of the 19th century both of those views seemed pretty
        sensible. Now the view that molecules are genuine things is one out
        because Einstein showed that Brownian motion depends on the effects of
        particular molecules. So if you postulate the existence of molecules
        and their sizes then you can generate Brownian motion, but if you
        postulate that water is continuous then you cannot explain Brownian
        motion. A way to undermine mathematical realism is to say that numbers
        are like what molecules were like before they played an explanatory
        role.
    \item
        But even the explanations without numbers don't seem to be particularly
        good explanations. For example in theoretical physics we just plug
        numbers into models and that's our explanation. For example, in
        Newton's Principia his explanation of why the planets have elliptical
        orbits (too hard for Vann), but Feynman's explanation of why the
        planets have elliptical orbits really makes it seem simpler than it
        really is. Feynman gives an explanation of how the orbits come out of
        the original equations from Newton etc. So it seems to Vann like
        Newton's explanation of why planets have elliptical orbits is the best
        possible explanation you can give, but this is a purely mathematical
        document. So the idea that mathematics does not explain things seems
        pretty ridiculous.
    \item
        One thing that is going on that is making this more complicated than
        we'd hoped is that if the law of gravitation is always stated in a
        particular way, but it's not quite right in that what matters is that
        the ratio of the product of the masses to the square of the distance is
        a universal constant of nature. For any choice of units of measure,
        there is a number that is $G$ and it'll follow from that that if you
        choose different units of measure you get a different numerical value
        for $G$ but all the calculations would go unchanged except for a
        constant factor. Back when people were engaged in the enterprise of
        trying to formalize unified science on a uniform basis, they were
        worried about things like whether they needed to include inpure numbers
        in the structure of the universe. The conclusion of that discussion was
        that they didn't need impure numbers. Different people are the same
        height, so there is something that they share regardless of what
        numbers you use. The thought at the time was that we don't need impure
        numbers, instead of asking what is John's height we'll ask what is
        John's height in inches. So with $G$ you say that it is a physical
        quantity with a somewhat odd status but we don't have to worry about
        that because we'll just pick units of measure and relative to the unit
        system you use you get a value for $G$.
    \item
        we do have pure constants in defining $\mu_0$ in regards to electric
        polarizability of a vacuum. these are physical constants in maxwell's
        equations that we would want to say are actual quantities. so maybe
        even $\pi$ has to be a physical quantity. you cannot get john's height
        as a number until you stipulate a system of measurement. on the other
        hand, $\pi$ isn't arbitrary; it's going to be the ratio of the
        circumference of a circle to it's diameter, and it isn't relative to any
        choice of measure. and $\pi$ appears in a lot of physical laws. 
    \item
        Why can we say that circles exist and that numbers don't? Doesn't the
        same reasoning apply?
    \item
        Back to the law of gravitation, the force matters because knowing the
        force allows you to know how the position is going to vary because of
        $F = ma$. One thing that is sort of interesting here is that people
        think of $F = ma$ as a law of nature, but it's only because of a
        coordinated choice of the units of measurement that you have equality
        here. If you had chosen different uses of measure you'd have $F = 73ma$
        or something and that would express the same law. But the really odd
        thing is that we're looking at the acceleration of the Earth-for that
        notion to make sense we have to suppose that the Earth has a trajectory
        and not only that but that there is a function that will predict its
        location at any particular point in time. Not only is there such a
        function but it's differentiable twice, so we have to treat the
        trajectory as something that is physical real in order for computations
        that use the law of gravity to determine how the planets are going to
        move. Philosophers are constantly saying that the only things that are
        real are going to be bodies, but it is hard to see how you could do
        basic physics if all you suppose is that all you have are bodies
        without supposing that the motion of the bodies can be described by
        ascribing a trajectory to them. Why that matters is that if a body has
        a trajectory then that trajectory is going to be isomorphic to the real
        line, so Newtonian physics seems require that bodies have trajectories
        and the trajectory is something isomorphic to the real line, so
        Newtonian physics requires something to be physically real that is
        isomorphic to the real line. But what we've learned from structuralism
        is that to say that there is such a thing as the real line is that
        there just needs to be something that is isomorphic to the real line.
        So the real line exists!. All Dedekind required was a complete ordered
        field that satisfies the properties. Well the moral of structuralism is
        that we complete of every complete ordered field as an isomorphic copy
        of the real numbers, but there isn't actually one such thing as the
        real numbers but just the isomorphisms. So what is needed to make real
        analysis true is that there must be something that satisfies the axioms
        of real analysis. That's a pretty outlandish confusion-that this
        physical theory would guarantee the existence of numbers-but what is
        doing the work here is structuralism.
    \item
        For next week let's talk about Hartry Field's idea that we don't really
        need numbers. This is very similar to Barkley.

\end{enumerate}

\section{April 19, 2017: Benacerraf on Mathematical Knowledge}

\begin{enumerate}
    \itemsep0em 
    \item
        Benacerraf had several skeptical arguments that were highly
        influential. One of them was based on a question: everybody agrees that
        if you know something, then you believe it and that if you know
        something, then it is true. But everyone also agrees that just having a
        true belief is enough for you to count yourself as having knowledge.
        Benacerraf proposes that for your true belief to count as knowledge it
        has got to be the case that the thing you believe has to have caused
        your belief. Benacerraf notes that facts about mathematical objects do
        not cause anything, and that mathematical beliefs cannot have been
        caused by anything that is going on in the realm of mathematics because
        nothing in the realm of mathematics has any affect on us at all. So
        there's a two prong argument: the arguments about the inscrutability of
        reference tell us that our beliefs purport to be about mathematical
        objects but our beliefs don't have the right kind of connection with
        the things about which they are supposed to be about. The second line
        of defense is, even if you say you have beliefs about mathematical
        objects for the sake of argument, since they are not caused by those
        objects those beliefs are not knowledge.
    \item
        One form of skeptical argument is to say that there aren't any
        mathematical objects. Benacerraf is not going for that form of
        argument, but he's just saying that if there are objects then we don't
        know about them.
    \item
        For example, Fermat's last theorem is an example of a justified belief
        that was not true for Fermat when he came up with it. He thought that
        he had a proof, but if he had looked closely at the proof he would've
        realized that it was not actually a proof. So it's not clear that his
        belief really was justified. It often happens that we form a mistake
        and then look more closely and realize it and correct it.
    \item
        Outside mathematics, few people are going to doubt that if you know
        something then you belief it. What is more vulnerable to doubt is the
        further contention that if you know something, then you believe it and
        the belief was caused by the thing you know. It seems to make the most
        sense about tangible things, but we would need an additional condition
        for things like patterns or abstract objects. Causation does not
        necessarily interact well with patterns. If we take true belief and add
        that it's a belief that is caused in an appropriate way by the thing
        about the belief is enough, the questions are whether that is enough to
        make it knowledge and if you have knowledge then do you have to have
        this causal condition in addition to being a justified belief. Starting
        with the idea that, at the very least, if you know then it is true and
        you believe it then is that necessary or sufficient to get you
        knowledge? Benacerraf is arguing that the extra condition is necessary
        because what is he trying to show is that we do not have mathematical
        knowledge, and for that he needs to show that there is a necessary
        condition that is not fulfilled by our purported mathematical
        knowledge.
    \item
        Her is something that looks like a problem for Benacerraf: knowledge of
        the future. If you have knowledge about things that are going to happen
        in the future, but since the future event has not caused your current
        belief. It seems like knowledge of future events is based on knowledge
        of current events. "I know I am going to die" is not causally dependent
        on my death in the future. The Benacerraf condition for your future
        death is that your death must have caused me to belief I am going to
        die, and this is false. So the causal condition that Benacerraf lays
        out seems to be too demanding. But wouldn't he just say that you don't
        actually know that you're going to die? So just concede that you don't
        have knowledge about the future. Also disjunctive claims seem to
        disprove this: "I know that either I am going to die or I am not going
        to die". But Benacerraf would have to deny this. 
    \item
        The logical truths also seem like they are not going to be causes of
        anything. Also tautologies seems to be trivial and not have any
        propositional content.  And we can assimilate mathematical truths with
        tautologies. This is why the case of logical knowledge is particularly
        important for us because there close analogies between logical
        knowledge and mathematical knowledge. It could be that we're able to
        say that we have logical knowledge without expected causal connection,
        maybe we have to say about mathematical knowledge. Maybe for synthetic
        and analytic claims are also such that the latter doesn't need a causal
        connection. You have to have a connection to Tom to know that he is a
        bachelor, but you don't have to have a connection to him to know that
        if he is a bachelor than he is married. It seems to go awfully far down
        the path of easy disbelief to say that we don't know that each of us
        will have mass and occupy space assuming we're alive tomorrow. The fact
        that I will have mass is something that will happen to tomorrow and so
        cannot causally interact with me today and yet it still seems to really
        undersell our capacity to know things. 
    \item
        Benacerraf is going to have to deny that there is any synthetic a
        priori knowledge, even though we can get an exception for analytic
        knowledge. He gets the stuff about causal conditional knowledge mostly
        from Alvin Goldman who explicitly allows an exception for logical
        knowledge. But it seems like I can know that Cherry is going to
        continue to be warm-blooded (assuming she is still alive), or that the
        conditional "If Cherry is alive tomorrow, then she will be warm
        blooded".
    \item
        One traditional way to try and cash out this idea is to say that
        we know general laws by induction (e.g. every dog anyone has ever seen
        has been warm blooded. and so draw the conclusion that all dogs are
        warm blooded). But inductive conclusions are never certain, because
        they are conditioned on your past experience. So this generalization
        may hold up in the future, but you cannot be certain about this. So if
        you don't require that knowledge does not necessarily need to be
        certain, in that you can just provide inductive evidence for a claim
        that have affected you, and you your beliefs for each particular dog
        being warm blooded fits the pattern. The observation that Cherry is a
        dog can lead to the conclusion that she will be warm-blooded tomorrow,
        so maybe what is going on is that Goldman was on the right path but
        just that he exaggerated because you can allow for uncertainty into
        knowledge.
    \item
        Can we just do what Russell did with "If there are an infinite number
        of individuals, then P" when he added the Axiom of Infinity. Vann:
        unless you know that there are infinitely many things, then it doesn't
        look like you have knowledge. Instead of mathematical knowledge being
        knowledge of certain things, is mathematical knowledge is just a set of
        conditionals about possible existing things? Russell as a logicist
        really thought that mathematical knowledge is logical knowledge, and
        we've already allowed an exception to the causal theory of knowing for
        logical knowledge (Cherry is or is not a dog). But does that challenge
        Benacerraf's objection? Then there is no need for causation in the
        theory of mathematical knowledge and so Benacceraf's implicit premise
        that mathematical knowledge is a different kind than logical knowledge
        can be disputed. His belief to that effect is informed by the logicist
        program which was pursued by a lot of smart people and ended up not
        working. So it looks like Benacerraf is going to resist the idea that
        mathematical knowledge is a species of logical knowledge. He would
        agree the speculative possibility that if logicism was successful then
        Benacerraf's objections wouldn't matter. 
    \item
        But mathematical and logical knowledge are similar in that they are
        both necessary and neither relies on facts about the world to be true,
        and so they have the same epistemic properties. Benacceraf is going to
        deny this: there is a tradition that the truths of logic are analytic
        in that you can know them from reflecting on their content, but the
        truths of mathematics are synthetic a priori. Arithmetic knowledge
        doesn't come to us by experience (don't touch, taste, feel mathematical
        objects). G\"odel thought that we had some mental faculty for
        recognizing mathematical truths, and that mathematical truths forced
        themselves upon us in much the same way that other experiences do. He
        thought there was something roughly analogous to perception that
        enabled us to recognize arithmetical truths. If that's right then there
        is no problem, because we get mathematical truths from experience in
        the same way we get other truths about the world. They thought that
        before we were embodied we were able to have direct perception of the
        world of mathematicals. If that story is right then there is no
        particular problem about the epistemic status of mathematics. It's
        pretty hard to convince yourself that there is some kind of sense organ
        that detects mathematical truths the same way our eyeballs detect
        light. So you don't have to dismiss the idea because it was G\"odel.
        Kant clearly saw the gap there and quickly proposed that we had
        knowledge that is synthetic a priori, which people thought was highly
        credible for a long time, but now most people do not find that view
        credible mostly because of non-Euclidean geometry.
    \item
        The idea that all our synthetic knowledge has to be caused by what it
        is about does not seem right, even if just because of our inability to
        have knowledge about the future. A variant of that view that might fair
        better was proposed by Robert Nozick: if I know something, I believe it
        and its true, and moreover if the belief hadn't been true I wouldn't
        have believed it. What it wants to rule out is counting accidentally
        true beliefs as knowledge, for example beliefs you have because of
        magic 8 balls that happen to be true. On the other hand, if you think
        of a belief you get by examining something, then if it wasn't true then
        you wouldn't have had the belief to being with. What about necessary
        truths and if I believed that $2 + 2 = 5$? The thought that people have
        is that if the things your beliefs are about were actually
        hallucinations. If numbers weren't there, it would make any difference
        to what my beliefs are. Also if we believed $2 + 2 = 5$ even if numbers
        do not exist what does that entail about mathematical knowledge? But
        the standard semantics for counterfactuals does not apply to the
        material conditionals of mathematics. The standard Stolniker semantics
        say that for a conditional $a \rightarrow b$ to be  true then you look
        at the closest possible world where $a$ is true and then see if $b$ is
        true. If there is not such close possible world or if $a$ is not true
        in any of them then the conditional is still true.
    \item
        Vann wanted to cover the Benacerraf argument and then ask whether the
        indispensability argument counters that and shows that we really do
        have mathematical knowledge. So we only did one of the things and we'll
        do the other next time.
\end{enumerate}

\section{April 24, 2017: Confirmational Holism}

\begin{enumerate}
    \itemsep0em 
    \item
        If knowledge is synthetic, then you have to be able to point to the
        cause of that knowledge. We're looking Benacerraf's arguments about
        mathematical knowledge and criticisms against the causal theory of
        knowledge. To a belief to count as synthetic knowledge, the belief has
        to have been caused by whatever it is the knowledge is about. The
        causal theory of knowledge is too demanding because it doesn't even
        seem to allow us to have knowledge of the future, but the idea
        underlying the Benacerraf complaint seems to have a lot of currency. If
        the knowledge is synthetic then it somehow has got to be grounded in
        experience, but you have to be able to tell the story about the causal
        change spawning the belief, and if you can't tell the story then the
        belief is not connected with the things in the world that make it true.
        We don't have an appropriate connection with respect to mathematical
        objects because they are not connected to experience at all. 
    \item
        Quine has an answer to that objection: it's a doctrine he gets out of
        Pierre Duhame and it is a doctrine of \textbf{confirmational holism},
        the idea that we can see a particular phenomenon like for say an
        experimental result as, say, establishing some result about what the
        world is right, is an oversimplification. We hypothesize that there are
        electrons, we want to know whether there are electrons, we perform an
        experiment that confirms the hypothesis and if we do enough experiments
        than we can know that there are electrons. Duhame says this is too
        simple because your experiments validity depends on all kinds of
        background assumptions that are required to get supposed connection
        between the experimental results and the hypothesis you're trying to
        confirm. For example, you get a result in the laboratory, but saying
        that the result signifies about what the world is right depends on a
        prior understanding of how your instruments work. You take for granted
        that the instrument works because earlier on people had to contemplate
        the instruments, but even if it's in the background the connection
        between the experimental observation and the hypothesis depends on
        background assumptions. Benacerraf tells us that the belief being
        confirmed has to be caused by the fact that your belief is true. But
        that's to say that an event has a single clause. The application of
        this argument to the causal theory of knowledge is: no, it won't be the
        case that the fact that $p$ was the cause of your belief that $p$
        because things never have a single cause. This is just a special case
        of the general idea that you never get a one-one correspondence between
        experimental results and hypothesis about what the world. This doesn't
        undermine the particular application to mathematical knowledge, but it
        does undermine the theory of knowledge. What does undermine it is the
        idea that you'll be able to say with assurance that this experimental
        result confirms this hypothesis or that it disproves it because the
        relationship is mediated by a body of theory. The body of theory might
        not be in doubt and so you may only be questioning the hypothesis, but
        this is just part of your psychological state. Quine took this idea
        that there are no crucial experiments and that you can never regard an
        experimental result as indubitably confirming or dis-confirming a
        scientific hypothesis. Quine took this idea and give it a nice slogan:
        "our theories face the tribunal of experience as a whole". Your
        expectations for what you're going to see when you look into the
        microscope are there because of a large body of theory that leads you
        to beliefs about what is under the microscope and how microscopes work.
        If you don't see what you expect to see, then your expectations were
        thwarted and so there is something that is wrong with the larger theory
        that is wrong but you can't specifically pick out which part of the
        theory is to blame. Going the other way, if you look into the
        microscope and you see what you expect to see, then that gives
        confirmation to the theory on the basis of which you had the
        expectations; but we can't say well, it left the old parts of the
        theory as is but only confirms this one hypothesis. But this is
        fallacious because you can either verify the entire theory or none of
        that.
    \item
        Quine is going to apply this argument against mathematical knowledge.
        We have this scientific theory that has mathematics deeply embedded in
        it as a part, and this theory has a really good track record
        successfully predicting the things we are going to experience. This
        means we should think of the theory as well confirmed. But confirmation
        is something that happens to a theory as a whole, so our whole
        scientific world view, broadly understood, goes up against reality and
        comes away victorious and by and large successful. The theory has this
        body of successes, the successes confirm the theory, and part of the
        theory is mathematics, which isn't something that you added onto the
        end. Mathematics is deeply embedded part of the theory, and so the
        theory of the whole is correct and so the mathematics is, too. Quine's
        extreme view was that all beliefs are interconnected as a web and he
        thought that there was nothing in the web that was so secure to be
        completely immune to doubt. So each of our beliefs are susceptible to
        doubt, and if we really wanted to cling to one belief we could just
        make adjustments somewhere else. He did think that there was a
        difference, though, in that there are some beliefs that are closer to
        the center of the web, some beliefs that are connected to almost
        anything else and so it would be very hard to separate them cleanly
        from the web of beliefs. So they are central beliefs that you are going
        to be really reluctant to change, peripheral beliefs are ones you can
        change much more easily. And he thought that logical and mathematical
        beliefs are part of this web near the middle. sometimes he say even
        logical beliefs are mutable, and other times he says that people talk
        about alternative logics but he thinks you can't really change your
        logic, so it is unclear what he really believes.
    \item
        So something that happened several times was that there was an idea
        that started in Quine and Putnam took it up and, as a general rule,
        Putnam made it sharper and clearer. So, we ascribe the indispensability 
        argument to Putnam and Quine. In Quine you never see him explicitly
        stating the argument and arguing for it (it's there, but tucked in);
        Putnam was the one who made it clear. Another example of that was the
        idea that maybe even tautologies are vulnerable to experimental
        refutation. That seems to be an accurate representation of Quine's
        views on knowledge, but he sometimes seems to say things that go the
        other way. The person who clearly embraced the idea that tautologies
        can be rejected on the basis of scientific experiment was Putnam. 
    \item
        Putnams' idea was that there is a long history of people thinking they
        knew things on a priori grounds, but it turned out that they not only
        did not know them on a priori grounds, but they turned out not to know
        them at all because they were false. For example, Euclidean geometry
        was supposedly synthetic a priori knowledge. But it turns out that,
        from General Relativity theory (and the experiments that confirmed it)
        is that Euclidean Geometry is not true. Putnam wants to take a step
        further; consider the double split experiment. What Putnam said was
        that this shows us that our classical understanding of the world fails
        so much harder than how we thought it could. But this experimental
        results shows that laws of logic fail at the quantum level. The fact
        that what you get if you have two slits and you ask how likely is it
        for the photon will pass through one of the slits, but $P(A) + P(B) \ne
        P(A \cup B)$. Putnam thought that the thesis that the photon passes
        through either slit A or slit B is different from the proposition that
        it passes through slit A or it passes through slit B and gets through
        even though the two claims should be tautologically equivalent under
        the sequential calculus.
    \item
        Quine's story is going to be that there is this web of belief and that
        things in the center of the web means a whole lot of the other things
        in the web depend on them, and so if you have an experience contrary to
        what you expected, you're going to have to modify your beliefs but as a
        general rule you don't want to disrupt your beliefs more than you need
        to and so given a choice you're going to be more inclined to disrupt
        the periphery beliefs rather than the core ones. Our mathematical and
        logical beliefs are near the center of the web of belief because
        mathematics is used so continually throughout the sciences that if you
        start messing with those (mathematics) you're going to see massive
        disruptions across the sciences. Most of the time you're going to want
        to avoid massive disruptions, most of the time you're going to want to
        adopt an adaptation that doesn't disrupt your system of beliefs a lot
        more than it has to. Mathematical beliefs are near the center and so
        mathematical beliefs are going to be such that you're going to give
        them up only very reluctantly. He doesn't think that any beliefs are
        immune to revision, but he thinks that they are near the center and so
        we're going to revise our mathematical beliefs only very rarely. That
        is why under the Quinian framework we want to seek empirical results
        that depend on mathematical results and that we're not going to be able
        to find the source of them unlike beliefs like "there are squirrels in
        the attic" because of the mathematical claims they depend on and so you
        can't reject your mathematical beliefs because they are so firmly
        connected to everything else, and you can't seek out a single empirical
        belief that is the result of the mathematical beliefs. Benacerraf wants
        to use the fact that we can't point to any experience that depends
        definitely on our mathematical beliefs, he wants to point to that as a
        reason for why our mathematical beliefs are not really know. Quine
        wants to turn that around and say that we're going to have a hard time
        coming up with any possible arrangement of knew evidence that would
        lead us to question our mathematical beliefs, but that just shows that
        our mathematical beliefs are right at the center of our web of beliefs
        and so are least likely to be the ones we can revise. So because we
        can't come up with a confirmation experiment for mathematical beliefs
        is only because of their centrality to our beliefs.
\end{enumerate}

\section{April 26, 2017: Quine's Confirmational Holism}

\begin{enumerate}
    \itemsep0em 
    \item
        I believe there are spies. I also believe that no two people are
        exactly the same height. It follows that there is such a person as the
        shortest spy. What Vann is wondering about is should we also say: I am
        ontologically committed to the shortest spy. The example is a
        descendant of an example of Quine: there is a shadowy figure in a
        trenchcoat who Ralph met on the beach, and Ralph suspected that the
        shadowy figure is the spy. That means that there is someone Ralph
        believes to be a spy. So it's true that Ralph believes that someone is
        a spy. Ralph also believes that there are spies. There is some
        particular person who Ralph believes is a spy, versus Ralph just
        believes generally about the world that there are spies. In the first
        case, we want to say that there is someone who Ralph believes to be a
        spy. In the second case, we don't want to say that there is someone of
        whom Ralph believes that person is a spy. The existence of the shadowy
        character on the beach tells us that $(\exists x)(believes(Ralph,
        Spy(x)))$ versus $believes(Ralph, \exists x (Spy (x)))$. So what is
        required for the de re (the first) reading to hold is that you have to
        be able to pick out someone as a spy in an appropriate way. For Ralph
        to believe that someone is a spy, it is not enough for Ralph to just
        believe that there is someone who is a spy. Nor is it enough for Ralph
        to be able to provide a name of someone he believes to be a spy. Ralph
        believes he can identify a spy with the phrase "the shortest spy", but
        this phrase as he uses it does not pick out its bearer in an
        appropriate way; there is not the right connection between Ralph's
        belief and the bearer of the name for us to conclude from the fact that
        Ralph believes the shortest spy is a spy that Ralph has a particular
        shortest spy in mind. From that particular starting point, thinking
        about ontological committments. A central question in the philosophy of
        mathematics is whether we should be ontologically committed to
        mathematical objects. Thinking in that context, Vann wants to know if
        the fact that I believe that there are spies and that there are no
        people with the exact same height is enough for me to be ontologically
        committed to the shortest spy.
    \item
        One approach to this question is to consider that there are fictional
        stories that contain characters and names that in terms of the internal
        dramatic structure of the story play the same role as names of people,
        but do not play that role totally because that story is a fiction.
        There are also news stories with contents that we believe are true, and
        we believe that the names in those news stories do refer to actual
        people. The interesting case is when you have a story that you do not
        know to be either truth or fiction, and there are names in that story
        where you can ask whether the name actually refers. In the mid
        19th-century is was the consensu opinion of all the scholars that the
        Illiad was a completely mythical story. In the philosophy of
        mathematics, are the numerals supposed to be treated as they are in
        stories that may or not be fictitious. Is this a good way to think of
        the ontological question. Mathematics is the story people tell one
        another; the philosophical question is whether the story is really
        true, and the way to ask that is to ask whether the number 17 really
        exists. 
    \item
        Quine set the stage for how people think about ontological questions.
        He said that this was the wrong way to think about it. He thought you
        were supposed to ask whether the name being referred to actually
        exists, because to ask the question that way is to presume that 17 does
        exist because 17 is the thing that the name refers and if there is no
        17 than the name doesn't refer. A great project of Quine's life was to
        fight off Meinong. Meinong had this idea that in addition to the things
        that exist, there are also things that don't exist like the Golden
        Mountain. So if you imagine a thing of a certain then it still has some
        kind of existence. 
    \item
        Quine wants to reject this because he wants to
        reject the ideas of grades of existence. He also wants to fully reject
        quantified modal logic, he has this paper "Three grades of modal
        involvement". The least incriminating grade is when we talk about
        necessity as an attribute of sentences. The version of necessity Quine
        regards as harmless. There is a second grade where you have modal
        operators applied to sentences, where if the sentence expresses a
        necessary truth then you can express that fact about the status of the
        sentence by putting a necessarily in front of it. Quine thinks that
        this is not so bad because in saying "Necessarily bachelors are
        unmarried" all you are saying is that the sentence "Bachelors are
        unmarried" is unnecessary, and so there is this confusion/misleading
        way of talking from Carnap where you take this metalinguistic statement
        and pull it down into the object language but prefixing a modal
        operator. So "Necessarily, all bachelors are unmarried" is a fine
        ascription but it's misleading because of the metalinguistic crossover.
        The worst kind is where you apply the necessity operator to sentences
        with free variables, where we want to say that if something is a brown
        dog then it is necessarily a dog but only contingently brown.
    \item
        Vann took a class from Quine at Harvard, he taught Phil 140:
        introduction to logic and stood up in Emerson Hall and read 3x5 index
        cards without looking up for the entire class. It was only much much
        later that he discovered that Quine was, in fact, Quine and that if you
        got him out of the lecture hall he is actually witty and entertaining.
        The reason why he did that is that he worked very hard at getting
        Methods of Logic so that said exactly the things he wanted to say in
        precisely the way he wanted. If he gets up and just started talking he
        would only say something approximately the same, but what was actually
        going to be beneficial was to actually read the book. Vann also went to
        one of its graduate seminars where he had Set Theory and its Logic
        written on 3x5 cards that he read without ever looking up.
    \item
        So a connection between modal logic and Meinong is that a reason people
        were willing to go in for quantified modal logic was that they
        discovered a plausible semantics for quantified modal logic. The
        plausible semantics involved talking about individuals that exist only
        in other possible worlds. The first grade of modal involvement just
        talks about sentence, but we're going to be committed to sentences so
        that is okay. You can introduce the modal operator without introducing
        ontological committments, but the semantics for the modal sentential
        calculus require that we can talk about other possible worlds, so we
        need to allow the existence of worlds other than the actual world. That
        looks like we've plunged into deep mysticism, but it's not really that
        bad because we talk about something being possible as it's being true
        in some other possible world, but that just be a vivid way of talking.
        You could also say that something is possibly true if there is some
        complete, consistent theory in which it is true. But the idea of a
        possible world in the sentential calculus is just an index, it does not
        have to be anything like what the world is like. In fact, the origin of
        the semantics for modal sentential calculus came in work of McKinsey,
        Tarski, and Johnson in the 1940s. In their initial work "possible
        worlds" were just points in a topological space where necessity took a
        set of points to its interior and diamond took a set of points to its
        closure. In, the third grade of modal involvement, we not only talk
        about possible worlds but we also talk about possible individuals in
        possible worlds. At that point, we're really drinking the Kool Aid.
    \item
        So the thought is that once we adopt the semantics for quantified modal
        logic then we find ourselves talking about individuals that exist only
        possibly, so we get these things that don't exist that have something
        like an outer domain consisting of all possible individuals, and then
        within it we have a sub-domain comprising those among the possible
        individuals that happen to actually exist. So if we have a robust sense
        of reality, then we're going to want to reject this idea that there are
        things that don't exist. What exists, exists; there aren't these other
        things that have these shadowy existence. That at least is what Quine
        wants to tell us. He wants to reject quantified modal logic because he
        thinks once you go down this path you're going to end up with
        non-existent things. And what is, is, and what is not, is not. There is
        a philosophical doctrine for you.
    \item
        What would Quine respond to the question of whether we necessarily
        exist? He would have to deny that the question is sensical because he
        believes that there is only type of existence. It seems pretty shocking
        that he's committed to this view. What he says is that acceptance of
        quantified modal logic plunges into the nightmare jungle of
        Aristotelian essentialism.
    \item
        How does Quine deal with counterfactuals? Is he going to say that every
        counterfactual statement is false? If you reject quantified modal
        logic, then you reject counterfactuals and can't seem to say that much.
        You can also say stuff like "If the Reimann Hypothesis holds, then this
        algorithm will terminate within these bounds". Quine can't distinguish
        between something like a mathematical implication and things like "If
        we're here on Monday, then we'll be in class". And clearly
        counterfactuals are going to be a problem for Quine. There is a story
        that people tell about counterfactuals whose best statement is a paper
        by Nelson Goodman called "The Problem with Counterfactuals". It's that
        you regard a counterfactual as true if it the consequent follows by law
        if it is entailed by the antecedent and some certain set of background
        assumptions. He thinks that the problem of counterfactuals is a serious
        problem because you seem to need a theory of counterfactuals to get an
        understanding of disposition terms. And without some good account of
        disposition terms you can't really have a good philosophy of science.
        So you want to account for what it means to say that "something is
        soluble" or "something is an electrical conductor" even if you never
        put it in water or apply an electrical voltage to it. You want to say
        that something is an electrical conductor if when somebody applies a
        voltage to it, then it conducts the electricity. But things that never
        have a voltage applied to them do not entail that those things are
        conductors, so you have to exclude them. So many of the key terms of
        science are disposition terms, and we don't seem to be able to get a
        clear acocunt of disposition terms if we can't get a clear account of
        what is going on with counterfactuals. Goodman had this idea that we
        can conlude the material conditional (if a voltage is applied to this,
        current will pass through). So there is a beginning of a story there
        and Goodman worked very hard at trying to fill in the stroy but kind of
        gave up, and the study of counterfactually pretty much stalled there
        until Stalnaker took up the question. So possible worlds seem like they
        are metaphysically costly because they apparently involve these shadowy
        entities that are there in some sense even if they don't exist. But as
        theoretical entities they are able to carry their weight because you
        need them to understand counterfactuals and it seems like you need them
        to understand propositional attitude constructions. 
    \item
        Quine didn't flat out reject counterfactuals, but he did think there
        was something dubious about them. Example: both of these are things
        that you could say. "If Caesar had been a commander in Korea, he
        would've used the atom bomb" and "If Caesar had been a commander in
        Korea, he would've use catapults." There is some level of context
        dependence so that what counterfactuals are true does not just depend
        on your idea of what the world is like, but also on what is important
        to you. With the math examples (If the Reimann hyptohesis were false),
        the standard semantics doesn't take account of them because it says
        that to say that a counterfactual is true you look at the nearest
        possible world in which the antecedent is true and ask whether the
        consequent is true in that world. But for mathematical statements, if a
        statement is true then it is necessarily true and similarly if its
        false, so you want to look at the nearest possible world in which the
        Reimann Hypothesis is false.  Quine seems to have to force all
        conditionals to collapse into material conditionals, and if he wants to
        avoid talking about possible worlds.  Even with Goodman's account he
        takes a specific possible world and makes it so we talk about it as if
        it were not a possible world. Quine  thinks that if you want a theory
        that is clear and explicit, the way to do that is to formulate your
        theory in the first-order predicate calculus. He realizes that we don't
        talk that way, but his idea is that it's part of the job of philosophy
        to see how to take both the statements of regular people and scientists
        and reformulate them in a way that's clear, correct, and precise.
        That's not on the frontlines of scientific work, it's rather a clean-up
        after science has made the big discoveries. Part of what philosophy
        does is to make things clear and explicit that were kind of brushed
        over and to try and unify and clarify. To unify and clarify a theory,
        the best option is to formulate it in the first-order predicate
        calculus. Part of what leads him to think that modal logic is such a
        mess (he worries about things like the possible fat man in the doorway
        (is there only one of them? could there be a bunch of them? are there
        more possible thin men in the doorway then possible fat man in the
        doorway), but he thinks it is such a waste of time to deal with all
        those. So part of the reason to go for the predicate calculus is to
        avoid modality and propositions and things because in order to really
        understand something you have to have clear identity conditions for it.
        We don't have clear identity  or individuation conditions for
        propositions or modalities, but we do have these for sets and so if we
        want a really good theory we need to stop talking about properties and
        rephrase everything that we would want to be a property in terms of
        just classes. Properties are tough because we don't have a good grasp
        on when two properties are the same, but have a great grasp of when two
        classes are being the same. So talk about the class of brown things
        instead of the property of being brown, etc. There is also the
        historical fact that in the first half of the 20th century,
        mathematicians got into immense tangles because they were trying to
        work within higher-order logics that classified things into logical
        types that turned out to be a bad approach, not in terms of any broad
        philosophical picture but rather in terms of what is successful
        mathematically because what is successful turned out to be giving up
        the theory of types and go straight with the first-order predicate
        calculus. If you want to understand a person's ontological commitments,
        ask them to formulate the theory they want to tell as a enumerated set
        of axioms in the first order predicate calculus because then you will
        know what their ontological commitments are. So to ask whether someone
        is committed to the shortest spy, don't bring in these non-existent
        things from possible world, just ask whether you belief there is a
        unique spy who is shorter than every other spy. So to make any real
        progress in ontology, you want to avoid getting bogged down in things
        like which of these possible things exist or which of these things that
        subsist actually exist. If we want to make real progress we want to
        simplify the logic so as to make things as clear as possible, and that
        requires formulating things in the first-order predicate calculus. This
        is what Quine recommends. If you want to make real progress, you need
        to be explicit about what the ontological commitments of your theory
        are, and to do that you jneed to formulate the theory in the
        first-order predicate calculus and then look at what existential
        sentences are true. If your there shows that there exists a so-and-so,
        then your theory is committed to so-and-so. If you formulate your
        theory in the first-order predicate calculus, then you have a definite
        ontological opinion that people can evaluate and disagree or agree
        with. If you don't do that or refuse to, then Quine thinks that you're
        refusing to make your own ontological commitments plain.
    \item
        Vann thought we were going to finish the indespensability argument, but
        we will just try that again next week.
\end{enumerate}

\section{May 1, 2017: Vann's Softened Indispensability Argument}

\begin{enumerate}
    \itemsep0em 
    \item
        Vann wants to begin today presenting a different take on the
        indispensability argument, and he knows that on sociological grounds
        that what he is going to say has got to be wrong because the
        indispensability argument has been discussed by a lot of people, a lot
        of them were a lot smarter than Vann and didn't come up with that idea. 
    \item
        Two features of the indispensability argument, one of which we have
        already talked about (that it depends on a hypothesis of confirmational
        holism where knowledge is a interdependent corporate body). If you've
        just been presented with the causal theory of knowledge in the way that
        Benacerraf presents it, then the confirmational holism seems like a
        welcome change because the causal theory seems far too demanding. For
        each of our well-established beliefs that counts as knowledge we can
        point to something in experience that causes that belief, but that view
        seems way too strong. It still seems plausible that there is something
        in between.
    \item
        Another feature of the indispensaiblity argument is that the conclusion
        it draws is something methodological. You look at the recent history of
        science and convince yourself that a methodology that forbade
        mathematical reasoning would be inadequate for the purposes of science,
        and so  you've convinced yourself that we need mathematics in order to
        do science. That's what the indispensability argument shows, the
        conclusion that people wnat to draw from it is that there are numbers.
        In order to get that there are numbers, you need to get from:
        scientists needs to assume that there ar enumbers in order to do their
        work to that there are numbers. So you really need to some form of
        transcendental argument to make that leap. 
    \item
        That step seems awfully dubious. It seems a lot like wishful thinking:
        we're going to get into trouble if there are not any numbers and so
        there must be numbers is not a particularly strong argument. Well, if
        you're trying to choose a theory, it looks like other things being
        equal you're probably going to choose the theory in which there are
        numbers otherwise. But you don't really have the ability to make the
        conclusion that there are numbers, you just need to be able to say that
        you're making certain assumptions in order to carry out certain
        computations and calculations that require that you reason as if there
        were numbers. So we better at least be willing to pretend that there
        are numbers, we need to be able to reason about scientific contexts as
        if there were such things as numbers. Having a methodology that
        fundamentally relies on pretext is disreputable and dishonest, wouldn't
        it be better if we move forward with things as they are without having
        to engage in some forms of elaborate pretense. That seems like a pretty
        good argument, but it doesn't seem like a compelling argument. We need
        to reason as if there were numbers, the easiest story to tell is just
        to say that there are numbers.
    \item
        One concern that people might have is that having the pretense of
        numbers allows you to explain current phenomena and explain what you
        observe, it seems to take some of the credibility to make predictions
        off of that. Vann thinks that this may go the other way: if you think
        that there is a chance that future experience is going to empirically
        show mathematics for the fraud it is, well the whole brief against
        mathematical knowledge is that these mathematical judgments were
        neither confirmable nor refutable by experience. If you think, well no,
        there may be some experience that could refute mathematics, then it
        looks like, okay, there could be experiences like that but we haven't
        had experiences like that. Well the fact that we haven't had any
        conflicts seems like a reason that the totality of scientific
        experience confirms the mathematics. If you think that mathematics
        cannot be confirmed by our experience, whatever experience is, well if
        you think that it can be disconfirmed by our experience that it really
        isn't off in its own world. 
    \item
        If all you need to do is compute things, then does this change
        anything? It does seem like applied mathematics that can actually be
        pretty complicated, in that the geometry people had to develop for the
        purposes of special relativity was a lot more complicated than the
        geometer mathematicians working on their own. On the other hand, if
        we're really worried about philosophers skepticism towards mathematics,
        it's that the philosopher 's inclination is to say that there aren't
        any numbers at all, and that mathematics is entirely fictional. There
        is plenty fo room for saying that there are numbers but that parts of
        the theory of numbers but that large parts of analysis. Vann doesn't
        think that philosophers don't have much to contribute to that
        conversation.
    \item
        Vann's crazy idea is really just taking what Putnam says at face value.
        Putnam points to an illustrative example of why mathematics is needed
        for science: the law of gravitation. The law of gravitation tells you
        that there is a number that marks a certain regularity in nature, that
        there are these ratios of physical quantities that is always the same
        (it doesn't change in time or based on the particular bodies it is
        relating). It is a ratio and this ratio is a number. So the law of
        gravitation asserts that there is a number that plays such and such a
        physical role. Therefore, there is a number--that is, the law of
        graviation entails the existence of numbers. We don't need
        methodological holism; the bit of methodology that everyone is
        committed to is that the logical consequences of well-confirmed
        theories are well-confirmed. You don't need any fancy methodology for
        that, just: you have good reason to believe $p$, and $p \rightarrow q$,
        then you have good reason to belief $q$. The fact that you have a good
        reason gives you sufficient justification by anybody's standard to
        accept $q$ and so we don't need the hypothesis of methodological
        holism, all we need is tha the consequences of well-confirmed theories
        is well-confirmed. So you have good reason to believe in the existence
        of numbers.
    \item
        Moreover, the way Putnam and Quine thought of the argument is tha they
        get this methodological conclusion that mathematics is necessary for
        science, and then you need some sort of transcendental argument to get
        to the conclusion that there are numbers, but we don't need to go that
        route the conclusion that we get from the law of gravitation is that
        there are numbers. So you don't get that the laws of classical
        mathematics are true by looking at the law of gravitation. Philosophers
        are worried skeptically about: not that classical mathematics gets the
        laws of the calculus wrong. The philosopher's worry is that there are
        not any numbers at all, because you are not able to encounter numbers
        physically. To answer that skeptical worry you don't need a big
        methodological premise, you just need the law of gravitation.
    \item
        How is this different than saying that the number of fingers on my hand
        to my hand is 5:1 so picking the law of gravitation is a good example.
        There's a level of reasoning that high school students can do that will
        get you there. Also Newton had a law that if you weigh something you
        determine what its mass is and so if you know what its mass is you know
        how it is going to respond to any kind of force that you pout it under
        (magnetic, weak/strong gravitational, pressure, etc.). This one number
        tells you all kinds of things about how the body is going to behave in
        a great variety of circumstances.
    \item
        One thing that Vann thinks is going on here is that you get the
        attitude that the question of whether there are numbers is a question
        about what metaphysical commitments you take on . You get that attitude
        from taking a perspective where you as a philosopher are able to stand
        outside of theories and select the best of several theories and the one
        that commit you to numbers seem to latch onto nature very simply, and
        the ones that deny there are numbers latch onto reality with great
        difficulty, if at all. That's a reason--the fact that mathematics
        figures so prominently in science--means that theories that commit
        themselves to numbers have a much easier time mediating the gap between
        our thoughts and nature and so that's a reason to go for that theory.
        Thinking of it that way, in terms of us being able to stand outside the
        process of scientific inquiry and choose one that we like best, that's
        an idea that figure really prominently in Carnap and that Quine
        rejected. Rather Quine said that developing science and developing a
        methodology of science happened at the same time. There is no way that
        we can just drop the science itself and just focus on the
        methodological part. There isn't a process from choosing among
        scientific theories that is different from just engaging in the process
        of science. The idea in Carnap that there are these ontological
        questions or external questions that are only answered by standing
        apart from science like this was a key idea of Carnap that Quine
        emphatically rejected. Well, if he had carried that thought through,
        then he would've seen that this argument doesn't just show something
        about the methodology of science, but also about the theory of science
        in that our best theories of science entail the existence of numbers.
        Surely some fragment of our scientific theories is well validated and
        so is the existence of numbers. 
    \item
        So there is a deviation from the tradition that mathematical knowledge
        has to be a priori. It doesn't mean that the knowledge is a posteriori,
        also if its a priori that doesn't mean that you can't get at it through
        experience. That in the old days would've been surprising, but Vann
        thinks this isn't really surprising anymore because the alternatives
        are either that mathematical knowledge is analytic which doesn't look
        promising because so many bright people failed at making that story
        work correctly. The other alternative is that mathematical knowledge is
        synthetic a prior, which also had a really great run but was really
        founded on Kant who didn't want to say that mathematical knowledge is
        synthetic a priori but rather that our knowledge of geometry is
        synthetic a priori, and Euclidean geometry has been pretty thoroughly
        thrashed qua not holding up physically.
    \item
        For all the statements that are well-confirmed, can you discern the
        nominalistic and platonistic content from these. In each case, the
        world has to be a certain way in order for each to be true. So we can
        think of them as conjunctions of nominalistic and platonistic content,
        but all the confirmation comes from just the nominalistic content and
        we never have any confirmation of the platonistic content. Vann thinks
        that this is the perfect question because next time we are going to
        talk about Hartry Field. To anticipate what is going to happen then,
        it's really hard to make out what's the nominalistic content of the law
        of gravitation. Things move without numbers, but things may not have
        instantaneous velocity without numbers. If you can succeed in singling
        out the nominalistic content of whatever scientific theory, then we can
        say the things we now say about forces and masses without bringing in
        any kind of numerical measurement. Maybe the nominalistic content could
        be phrased in terms of "if there are abstract mathematical objects,
        then XYZ." This is different from Russell because people couldn't agree
        on whether or not there were actually infinitely mathematical things as
        an empirical hypothesis. But the standard nominalist story is not just
        that there aren't any numbers, but if God had worked on the 7th day
        there would've been numbers but in fact there aren't any numbers. That
        doesn't seem like the standard nominalist position; it's more like, we
        know what things there are (physical things), and they just deny the
        existence of abstract things. Those things aren't even possible under
        the nominalist view; a standard mathematical view upon platonists is
        that these objects are possible and the nominalist is going to say that
        such abstract objects are impossible.

\end{enumerate}

\end{document}
